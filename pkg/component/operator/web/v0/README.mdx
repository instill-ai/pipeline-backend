---
title: "Web"
lang: "en-US"
draft: false
description: "Learn about how to set up a VDP Web component https://github.com/instill-ai/instill-core"
---

The Web component is an operator component that allows users to scrape websites.
It can carry out the following tasks:
- [Crawl Site](#crawl-site)
- [Scrape Page](#scrape-page)
- [Scrape Sitemap](#scrape-sitemap)

## Release Stage

`Alpha`

## Configuration

The component definition and tasks are defined in the [definition.json](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/operator/web/v0/config/definition.json) and [tasks.json](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/operator/web/v0/config/tasks.json) files respectively.



## Supported Tasks

### Crawl Site

Crawling involves navigating through the website, starting from a designated page (often the homepage) and systematically following links to explore and retrieve titles and links from other pages. Please notice that the crawler will not fetch the content of the pages. If you want to scrape the content of the pages, please use the `TASK_SCRAPE_PAGE`.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_CRAWL_SITE` |
| Root URL (required) | `root-url` | string | The root URL to scrape. All links on this page will be scraped, and all links on those pages, and so on. |
| Allowed Domains | `allowed-domains` | array[string] | A list of domains that are allowed to be scraped. If empty, all domains are allowed. |
| Max Number of Pages (required) | `max-k` | integer | Max-K specifies the maximum number of pages to return. If max-k is set to 0, all available pages will be returned, up to a maximum of 100. If max-k is set to a positive number, the result will include up to max-k pages, but no more than that. |
| Timeout | `timeout` | integer | The time to wait for the page to load in milliseconds. Min 0, Max 60000. |
| Max Depth | `max-depth` | integer | Max Depth specifies how deep the crawler will navigate from the root URL. If max depth is set to 1, the crawler will only scrape the root URL and will not follow any links to other pages. If max depth is set to 0, the crawler will scrape all reachable pages until the total number of scraped pages reaches max-k. If both max-k and max depth are defined, the crawler will prioritize the max-k setting when determining how many pages to scrape. |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| [Pages](#crawl-site-pages) | `pages` | array[object] | The link and title of webpages crawled by the crawler. |
</div>

<details>
<summary> Output Objects in Crawl Site</summary>

<h4 id="crawl-site-pages">Pages</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Link | `link` | string | The full URL to which the webpage link is pointing, e.g., http://www.example.com/foo/bar. |
| Title | `title` | string | The title of a webpage link in plain text. |
</div>
</details>

### Scrape Page

Scraping involves extracting specific data from a targeted webpage by parsing its HTML structure. Unlike crawling, which involves navigating across multiple pages, scraping focuses on a single page to retrieve only the relevant information. Once the specific content is scraped, the next step is manipulating it using [jQuery](https://www.w3schools.com/jquery/jquery_syntax.asp) in a specified sequence. The sequence of jQuery filtering data will be executed in the order of only-main-content, remove-tags, and only-include-tags. Please check the [jQuery Syntax Examples](#jquery-syntax-examples).

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_SCRAPE_PAGE` |
| URL (required) | `url` | string | The URL to be scrape the webpage contents. |
| Include HTML | `include-html` | boolean | Indicate whether to include the raw HTML of the webpage in the output. If you want to include the raw HTML, set this to true. |
| Only Main Content | `only-main-content` | boolean | Only return the main content of the page by excluding the content of the tag of header, nav, footer. |
| Remove Tags | `remove-tags` | array[string] | A list of tags, classes, and ids to remove from the output. You can use [jQuery](https://www.w3schools.com/jquery/jquery_syntax.asp) to remove data. If empty, no tags will be removed. Example: 'script, .ad, #footer'. Please check the [jQuery Syntax Examples](#jquery-syntax-examples). |
| Only Include Tags | `only-include-tags` | array[string] | A list of tags, classes, and ids to include in the output. You can use [jQuery](https://www.w3schools.com/jquery/jquery_syntax.asp) to include data. If empty, all tags will be included. Example: 'script, .ad, #footer'. Please check the [jQuery Syntax Examples](#jquery-syntax-examples). |
| Timeout | `timeout` | integer | The time to wait for the page to load in milliseconds. Min 0, Max 60000. Please set it as 0 if you only want to collect static content. Please notice that if the timeout is set a small value, the page may not be fully loaded. |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Content | `content` | string | The scraped plain content without html tags of the webpage. |
| Markdown | `markdown` | string | The scraped markdown of the webpage. |
| HTML (optional) | `html` | string | The scraped html of the webpage. |
| [Metadata](#scrape-page-metadata) (optional) | `metadata` | object | The metadata of the webpage. |
| Links on Page (optional) | `links-on-page` | array[string] | The list of links on the webpage. |
</div>

<details>
<summary> Output Objects in Scrape Page</summary>

<h4 id="scrape-page-metadata">Metadata</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Description | `description` | string | The description of the webpage. |
| Source URL | `source-url` | string | The source URL of the webpage. |
| Title | `title` | string | The title of the webpage. |
</div>
</details>


<h4 id="jquery-syntax-examples">jQuery Syntax Examples</h4>

- **Element Selector**: Targets all instances of a specific HTML tag.
  **Example**: `div`
  Extracts all `<div>` elements.

- **ID Selector**: Targets a single element by its unique `id` attribute.
  **Example**: `#header`
  Extracts the element with the `id` of `header`.

- **Class Selector**: Targets all elements with a specific class name.
  **Example**: `.button`
  Extracts all elements with the class `button`.

- **Attribute Selector**: Targets elements based on the presence or value of an attribute.
  **Example**: `[type="text"]`
  Extracts all elements with a `type` attribute equal to `text`.

- **Descendant Selector**: Targets elements that are nested within other elements.
  **Example**: `div p`
  Extracts all `<p>` elements that are inside `<div>` elements.




#### About Dynamic Content
`TASK_SCRAPE_PAGE` supports to fetch dynamic content from web pages while simulating user behaviors, such as scrolling down. The initial implementation includes the following capabilities:

Scrolling:
- Mimics user scrolling down the page to load additional content dynamically.

Future enhancements will include additional user interactions, such as:
- Clicking: Simulate mouse clicks on specified elements.
- Taking Screenshots: Capture screenshots of the current view.
- Keyboard Actions: Simulate key presses and other keyboard interactions.

This function aims to provide a robust framework for interacting with web pages and extracting dynamic content effectively.

### Scrape Sitemap

Scrape the sitemap information

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_SCRAPE_SITEMAP` |
| Sitemap URL (required) | `url` | string | The URL of the sitemap to scrape |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| List | `list` | array | The list of information in a sitemap |
</div>


## Example Recipes

```yaml
version: v1beta

variable:
  url:
    title: url
    instill-format: string

component:
  crawler:
    type: web
    input:
      root-url: ${variable.url}
      allowed-domains:
      max-k: 10
      timeout: 0
      max-depth: 0
    condition:
    task: TASK_CRAWL_SITE

  scraper:
    type: web
    input:
      url: ${crawler.output.pages[0].link}
      include-html: false
      only-main-content: true
      remove-tags:
      only-include-tags:
      timeout: 1000
    condition:
    task: TASK_SCRAPE_PAGE

output:
  markdown:
    title: Markdown
    value: ${scraper.output.markdown}
  links:
    title: links
    value: ${scraper.output.links-on-page}
```
