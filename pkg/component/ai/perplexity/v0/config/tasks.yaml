TASK_CHAT:
  title: Chat
  shortDescription: Generate response base on conversation input.
  input:
    title: Chat Input
    description: Input schema of the chat task.
    shortDescription: Input schema of the chat task.
    properties:
      data:
        title: Chat Data
        description: Input data.
        shortDescription: Input data.
        properties:
          model:
            description: The model to be used for `TASK_CHAT`.
            shortDescription: The model to be used.
            type: string
            enum:
              - sonar
              - sonar-pro

              # Deprecated models, unavailable after 2025-02-22
              - llama-3.1-sonar-small-128k-online
              - llama-3.1-sonar-large-128k-online
              - llama-3.1-sonar-huge-128k-online
            instillCredentialMap:
              values:
                - sonar
                - sonar-pro

                - llama-3.1-sonar-small-128k-online
                - llama-3.1-sonar-large-128k-online
                - llama-3.1-sonar-huge-128k-online
            title: Model Name
            uiOrder: 0
          messages:
            title: Chat Messages
            items:
              properties:
                content:
                  description: The message content.
                  shortDescription: The message content.
                  title: Content
                  items:
                    properties:
                      text:
                        title: Text Message
                        description: Text message.
                        shortDescription: Text message.
                        type: string
                        uiOrder: 1
                      type:
                        title: Text
                        description: Text content type.
                        shortDescription: Text content type.
                        type: string
                        const: text
                        uiOrder: 0
                    required: []
                    title: Text
                    type: object
                  uiOrder: 0
                  type: array
                role:
                  description: The message role, i.e. 'system', 'user' or 'assistant'.
                  shortDescription: The message role, i.e. 'system', 'user' or 'assistant'.
                  type: string
                  title: Role
                  enum:
                    - system
                    - user
                    - assistant
                  uiOrder: 1
                name:
                  description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
                  shortDescription: An optional name for the participant. Provides the model information to differentiate between participants of the same
                    role.
                  type: string
                  title: Name
                  uiOrder: 2
              required:
                - content
                - role
              type: object
            uiOrder: 1
            description: List of chat messages.
            type: array
        required:
          - messages
        uiOrder: 0
        type: object
      parameter:
        description: Input parameter.
        shortDescription: Input parameter.
        properties:
          max-tokens:
            title: Max New Tokens
            description: The maximum number of completion tokens returned by the API. The total number of tokens requested in max_tokens plus the number
              of prompt tokens sent in messages must not exceed the context window token limit of model requested. If left unspecified, then the model will
              generate tokens until either it reaches its stop token or the end of its context window.
            shortDescription: The maximum number of tokens for model to generate.
            type: integer
            default: 50
            uiOrder: 0
          temperature:
            title: Temperature
            description: The amount of randomness in the response, valued between 0 inclusive and 2 exclusive. Higher values are more random, and lower
              values are more deterministic.
            shortDescription: The temperature for sampling.
            type: number
            default: 0.2
            uiOrder: 1
          top-p:
            title: Top P
            description: The nucleus sampling threshold, valued between 0 and 1 inclusive. For each subsequent token, the model considers the results of
              the tokens with top_p probability mass. We recommend either altering top_k or top_p, but not both.
            shortDescription: Nucleus sampling.
            type: number
            default: 0.9
            uiOrder: 2
          stream:
            title: Stream
            description: If set, partial message deltas will be sent. Tokens will be sent as data-only server-sent events as they become available.
            shortDescription: If set, partial message deltas will be sent.
            type: boolean
            default: false
            uiOrder: 3
          search-mode:
            title: Search Mode
            description: Controls the search mode used for the request. When set to 'academic', results will prioritize scholarly sources like peer-reviewed
              papers and academic journals. When set to 'sec', results will prioritize financial and legal sources.
            shortDescription: Controls the search mode used for the request.
            type: string
            enum:
              - academic
              - web
              - sec
            default: web
            uiOrder: 4
          search-domain-filter:
            title: Search Domain Filter
            description: Given a list of domains, limit the citations used by the online model to URLs from the specified domains. Currently limited to
              only 3 domains for whitelisting and blacklisting. For blacklisting add a `-` to the beginning of the domain string.
            type: string
            uiOrder: 5
          return-related-questions:
            title: Return Related Questions
            description: Determines whether related questions should be returned.
            shortDescription: Determines whether related questions should be returned.
            type: boolean
            default: false
            uiOrder: 6
          search-recency-filter:
            title: Search Recency Filter
            description: Returns search results within the specified time interval - does not apply to images. Values include `month`, `week`, `day`, `year`.
            type: string
            uiOrder: 6
          search-after-date-filter:
            title: Search After Date Filter
            description: Filters search results to only include content published after this date. Format should be %m/%d/%Y (e.g. 3/1/2025)
            type: string
            uiOrder: 7
          search-before-date-filter:
            title: Search Before Date Filter
            description: Filters search results to only include content published before this date. Format should be %m/%d/%Y (e.g. 3/1/2025)
            type: string
            uiOrder: 8
          last-updated-after-filter:
            title: Last Updated After Filter
            description: Filters search results to only include content last updated after this date. Format should be %m/%d/%Y (e.g. 3/1/2025)
            type: string
            uiOrder: 9
          last-updated-before-filter:
            title: Last Updated Before Filter
            description: Filters search results to only include content last updated before this date. Format should be %m/%d/%Y (e.g. 3/1/2025)
            type: string
            uiOrder: 10
          web-search-options:
            title: Web Search Options
            description: Configuration for using web search in model responses.
            shortDescription: Configuration for using web search in model responses.
            properties:
              search-context-size:
                title: Search Context Size
                description: "Determines how much search context is retrieved for the model. Options are: low (minimizes context for cost savings but less\
                  \ comprehensive answers), medium (balanced approach suitable for most queries), and high (maximizes context for comprehensive answers\
                  \ but at higher cost)."
                shortDescription: Determines how much search context is retrieved for the model.
                type: string
                enum:
                  - low
                  - medium
                  - high
                default: low
                uiOrder: 1
              user-location:
                title: User Location
                description: To refine search results based on geography, you can specify an approximate user location.
                shortDescription: To refine search results based on geography, you can specify an approximate user location.
                properties:
                  latitude:
                    title: Latitude
                    description: The latitude of the user's location.
                    shortDescription: The latitude of the user's location.
                    type: number
                    uiOrder: 1
                  longitude:
                    title: Longitude
                    description: The longitude of the user's location.
                    shortDescription: The longitude of the user's location.
                    type: number
                    uiOrder: 2
                  country:
                    title: Country
                    description: The two letter ISO country code of the user's location.
                    shortDescription: The two letter ISO country code of the user's location.
                    type: string
                    uiOrder: 3
                required: []
                uiOrder: 1
                type: object
            uiOrder: 3
            type: object
          top-k:
            title: Top K
            description: The number of tokens to keep for highest top-k filtering, specified as an integer between 0 and 2048 inclusive. If set to 0, top-k
              filtering is disabled. We recommend either altering top_k or top_p, but not both.
            type: number
            default: 0
            uiOrder: 11
          presence-penalty:
            title: Presence Penalty
            description: A value between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the
              model's likelihood to talk about new topics. Incompatible with `frequency_penalty`.
            type: number
            default: 0
            uiOrder: 12
          frequency-penalty:
            title: Frequency Penalty
            description: A multiplicative penalty greater than 0. Values greater than 1.0 penalize new tokens based on their existing frequency in the text
              so far, decreasing the model's likelihood to repeat the same line verbatim. A value of 1.0 means no penalty. Incompatible with `presence_penalty`.
            type: number
            default: 1
            uiOrder: 13
          enable-search-classifier:
            title: Enable Search Classifier
            description: Whether to enable search classifier.
            shortDescription: Whether to enable search classifier.
            type: boolean
            default: false
            uiOrder: 14
        required: []
        uiOrder: 1
        title: Input Parameter
        type: object
    required:
      - data
    type: object
  output:
    title: Chat Output
    description: Output schema of the chat task.
    shortDescription: Output schema of the chat task.
    properties:
      data:
        description: Output data.
        shortDescription: Output data.
        properties:
          choices:
            title: Choices
            description: List of chat completion choices.
            shortDescription: List of chat completion choices
            items:
              properties:
                finish-reason:
                  title: Finish Reason
                  description: The reason the model stopped generating tokens.
                  shortDescription: The reason the model stopped generating tokens.
                  uiOrder: 0
                  type: string
                index:
                  title: Index
                  description: The index of the choice in the list of choices.
                  shortDescription: The index of the choice in the list of choices.
                  uiOrder: 1
                  type: integer
                message:
                  title: Message
                  description: A chat message generated by the model.
                  shortDescription: A chat message generated by the model.
                  properties:
                    content:
                      title: Content
                      description: The contents of the message.
                      shortDescription: The contents of the message.
                      uiOrder: 0
                      type: string
                    role:
                      title: Role
                      description: The role of the author of this message.
                      shortDescription: The role of the author of this message.
                      uiOrder: 1
                      type: string
                  required: []
                  uiOrder: 2
                  type: object
                created:
                  title: Created
                  description: 'The timestamp of when the chat completion was created. Format is in ISO 8601. Example: 2024-07-01T11:47:40.388Z.'
                  shortDescription: The Unix timestamp (in seconds) of when the chat completion was created.
                  uiOrder: 3
                  type: integer
              required:
                - finish-reason
                - index
                - message
                - created
              type: object
            uiOrder: 0
            type: array
          citations:
            title: Citations
            description: List of citations.
            shortDescription: List of citations.
            items:
              type: string
            uiOrder: 1
            type: array
          search-results:
            title: Search Results
            description: A list of search results related to the response.
            shortDescription: A list of search results related to the response.
            items:
              properties:
                title:
                  title: Title
                  description: The title of the search result.
                  shortDescription: The title of the search result.
                  type: string
                  uiOrder: 0
                url:
                  title: URL
                  description: The URL of the search result.
                  shortDescription: The URL of the search result.
                  type: string
                  uiOrder: 1
                date:
                  title: Date
                  description: The date of the search result.
                  shortDescription: The date of the search result.
                  type: string
                  uiOrder: 2
              required:
                - title
                - url
              type: object
            uiOrder: 2
            type: array
        required:
          - choices
        uiOrder: 0
        title: Output Data
        type: object
      metadata:
        description: Output metadata.
        shortDescription: Output metadata.
        properties:
          usage:
            description: Usage statistics for the request.
            shortDescription: Usage statistics for the request.
            properties:
              completion-tokens:
                title: Completion Tokens
                description: Number of tokens in the generated response.
                shortDescription: Number of tokens in the generated response.
                uiOrder: 0
                type: integer
              prompt-tokens:
                title: Prompt Tokens
                description: Number of tokens in the prompt.
                shortDescription: Number of tokens in the prompt.
                uiOrder: 1
                type: integer
              total-tokens:
                title: Total Tokens
                description: Total number of tokens used in the request (prompt + completion).
                shortDescription: Total number of tokens used in the request (prompt + completion).
                uiOrder: 2
                type: integer
            required:
              - completion-tokens
              - prompt-tokens
              - total-tokens
            uiOrder: 0
            title: Usage
            type: object
        required: []
        title: Output Metadata
        uiOrder: 1
        type: object
    required:
      - data
    type: object
