{
  "TASK_CHAT": {
    "title": "Chat",
    "shortDescription": "Generate response base on conversation input.",
    "input": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Chat Input",
      "description": "Input schema of the chat task.",
      "shortDescription": "Input schema of the chat task.",
      "properties": {
        "data": {
          "title": "Chat Data",
          "description": "Input data.",
          "shortDescription": "Input data.",
          "properties": {
            "model": {
              "description": "The model to be used for `TASK_CHAT`.",
              "shortDescription": "The model to be used.",
              "acceptFormats": [
                "string"
              ],
              "enum": [
                "llama-3.1-sonar-small-128k-online",
                "llama-3.1-sonar-large-128k-online",
                "llama-3.1-sonar-huge-128k-online"
              ],
              "instillCredentialMap": {
                "values": [
                  "llama-3.1-sonar-small-128k-online",
                  "llama-3.1-sonar-large-128k-online",
                  "llama-3.1-sonar-huge-128k-online"
                ]
              },
              "title": "Model Name",
              "uiOrder": 0,
              "format": "string"
            },
            "messages": {
              "title": "Chat Messages",
              "items": {
                "properties": {
                  "content": {
                    "description": "The message content.",
                    "shortDescription": "The message content.",
                    "title": "Content",
                    "items": {
                      "properties": {
                        "text": {
                          "title": "Text Message",
                          "description": "Text message.",
                          "shortDescription": "Text message.",
                          "acceptFormats": [
                            "string"
                          ],
                          "uiOrder": 1,
                          "format": "string"
                        },
                        "type": {
                          "title": "Text",
                          "description": "Text content type.",
                          "shortDescription": "Text content type.",
                          "acceptFormats": [
                            "string"
                          ],
                          "const": "text",
                          "uiOrder": 0,
                          "format": "string"
                        }
                      },
                      "required": [],
                      "title": "Text",
                      "format": "object"
                    },
                    "uiOrder": 0,
                    "format": "array"
                  },
                  "role": {
                    "description": "The message role, i.e. 'system', 'user' or 'assistant'.",
                    "shortDescription": "The message role, i.e. 'system', 'user' or 'assistant'.",
                    "acceptFormats": [
                      "string"
                    ],
                    "title": "Role",
                    "enum": [
                      "system",
                      "user",
                      "assistant"
                    ],
                    "uiOrder": 1,
                    "format": "string"
                  },
                  "name": {
                    "description": "An optional name for the participant. Provides the model information to differentiate between participants of the same role.",
                    "shortDescription": "An optional name for the participant. Provides the model information to differentiate between participants of the same role.",
                    "acceptFormats": [
                      "string"
                    ],
                    "title": "Name",
                    "uiOrder": 2,
                    "format": "string"
                  }
                },
                "required": [
                  "content",
                  "role"
                ],
                "format": "object"
              },
              "uiOrder": 1,
              "description": "List of chat messages.",
              "format": "array"
            }
          },
          "required": [
            "messages"
          ],
          "uiOrder": 0,
          "format": "object"
        },
        "parameter": {
          "description": "Input parameter.",
          "shortDescription": "Input parameter.",
          "properties": {
            "max-tokens": {
              "title": "Max New Tokens",
              "description": "The maximum number of completion tokens returned by the API. The total number of tokens requested in max_tokens plus the number of prompt tokens sent in messages must not exceed the context window token limit of model requested. If left unspecified, then the model will generate tokens until either it reaches its stop token or the end of its context window.",
              "shortDescription": "The maximum number of tokens for model to generate.",
              "acceptFormats": [
                "integer"
              ],
              "default": 50,
              "uiOrder": 0,
              "format": "integer"
            },
            "temperature": {
              "title": "Temperature",
              "description": "The amount of randomness in the response, valued between 0 inclusive and 2 exclusive. Higher values are more random, and lower values are more deterministic.",
              "shortDescription": "The temperature for sampling.",
              "acceptFormats": [
                "number"
              ],
              "default": 0.2,
              "uiOrder": 1,
              "format": "number"
            },
            "top-p": {
              "title": "Top P",
              "description": "The nucleus sampling threshold, valued between 0 and 1 inclusive. For each subsequent token, the model considers the results of the tokens with top_p probability mass. We recommend either altering top_k or top_p, but not both.",
              "shortDescription": "Nucleus sampling.",
              "acceptFormats": [
                "number"
              ],
              "default": 0.9,
              "uiOrder": 2,
              "format": "number"
            },
            "stream": {
              "title": "Stream",
              "description": "If set, partial message deltas will be sent. Tokens will be sent as data-only server-sent events as they become available.",
              "shortDescription": "If set, partial message deltas will be sent.",
              "acceptFormats": [
                "boolean"
              ],
              "default": false,
              "uiOrder": 3,
              "format": "boolean"
            },
            "search-domain-filter": {
              "title": "Search Domain Filter",
              "description": "Given a list of domains, limit the citations used by the online model to URLs from the specified domains. Currently limited to only 3 domains for whitelisting and blacklisting. For blacklisting add a `-` to the beginning of the domain string.",
              "acceptFormats": [
                "array"
              ],
              "uiOrder": 4,
              "format": "string"
            },
            "search-recency-filter": {
              "title": "Search Recency Filter",
              "description": "Returns search results within the specified time interval - does not apply to images. Values include `month`, `week`, `day`, `hour`.",
              "acceptFormats": [
                "string"
              ],
              "uiOrder": 5,
              "format": "string"
            },
            "top-k": {
              "title": "Top K",
              "description": "The number of tokens to keep for highest top-k filtering, specified as an integer between 0 and 2048 inclusive. If set to 0, top-k filtering is disabled. We recommend either altering top_k or top_p, but not both.",
              "acceptFormats": [
                "number"
              ],
              "default": 0,
              "uiOrder": 6,
              "format": "number"
            },
            "presence-penalty": {
              "title": "Presence Penalty",
              "description": "A value between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. Incompatible with `frequency_penalty`.",
              "acceptFormats": [
                "number"
              ],
              "default": 0,
              "uiOrder": 7,
              "format": "number"
            },
            "frequency-penalty": {
              "title": "Frequency Penalty",
              "description": "A multiplicative penalty greater than 0. Values greater than 1.0 penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. A value of 1.0 means no penalty. Incompatible with `presence_penalty`.",
              "acceptFormats": [
                "number"
              ],
              "default": 1,
              "uiOrder": 8,
              "format": "number"
            }
          },
          "required": [],
          "uiOrder": 1,
          "title": "Input Parameter",
          "format": "object"
        }
      },
      "required": [
        "data"
      ],
      "format": "object"
    },
    "output": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Chat Output",
      "description": "Output schema of the chat task.",
      "shortDescription": "Output schema of the chat task.",
      "properties": {
        "data": {
          "description": "Output data.",
          "shortDescription": "Output data.",
          "properties": {
            "choices": {
              "title": "Choices",
              "description": "List of chat completion choices.",
              "shortDescription": "List of chat completion choices",
              "items": {
                "properties": {
                  "finish-reason": {
                    "title": "Finish Reason",
                    "description": "The reason the model stopped generating tokens.",
                    "shortDescription": "The reason the model stopped generating tokens.",
                    "uiOrder": 0,
                    "format": "string"
                  },
                  "index": {
                    "title": "Index",
                    "description": "The index of the choice in the list of choices.",
                    "shortDescription": "The index of the choice in the list of choices.",
                    "uiOrder": 1,
                    "format": "integer"
                  },
                  "message": {
                    "title": "Message",
                    "description": "A chat message generated by the model.",
                    "shortDescription": "A chat message generated by the model.",
                    "properties": {
                      "content": {
                        "title": "Content",
                        "description": "The contents of the message.",
                        "shortDescription": "The contents of the message.",
                        "uiOrder": 0,
                        "format": "string"
                      },
                      "role": {
                        "title": "Role",
                        "description": "The role of the author of this message.",
                        "shortDescription": "The role of the author of this message.",
                        "uiOrder": 1,
                        "format": "string"
                      }
                    },
                    "required": [],
                    "uiOrder": 2,
                    "format": "object"
                  },
                  "created": {
                    "title": "Created",
                    "description": "The timestamp of when the chat completion was created. Format is in ISO 8601. Example: 2024-07-01T11:47:40.388Z.",
                    "shortDescription": "The Unix timestamp (in seconds) of when the chat completion was created.",
                    "uiOrder": 3,
                    "format": "integer"
                  }
                },
                "required": [
                  "finish-reason",
                  "index",
                  "message",
                  "created"
                ],
                "format": "object"
              },
              "uiOrder": 0,
              "format": "array"
            },
            "citations": {
              "title": "Citations",
              "description": "List of citations.",
              "shortDescription": "List of citations.",
              "items": {
                "format": "string"
              },
              "uiOrder": 1,
              "format": "array"
            }
          },
          "required": [
            "choices"
          ],
          "uiOrder": 0,
          "title": "Output Data",
          "format": "object"
        },
        "metadata": {
          "description": "Output metadata.",
          "shortDescription": "Output metadata.",
          "properties": {
            "usage": {
              "description": "Usage statistics for the request.",
              "shortDescription": "Usage statistics for the request.",
              "properties": {
                "completion-tokens": {
                  "title": "Completion Tokens",
                  "description": "Number of tokens in the generated response.",
                  "shortDescription": "Number of tokens in the generated response.",
                  "uiOrder": 0,
                  "format": "integer"
                },
                "prompt-tokens": {
                  "title": "Prompt Tokens",
                  "description": "Number of tokens in the prompt.",
                  "shortDescription": "Number of tokens in the prompt.",
                  "uiOrder": 1,
                  "format": "integer"
                },
                "total-tokens": {
                  "title": "Total Tokens",
                  "description": "Total number of tokens used in the request (prompt + completion).",
                  "shortDescription": "Total number of tokens used in the request (prompt + completion).",
                  "uiOrder": 2,
                  "format": "integer"
                }
              },
              "required": [
                "completion-tokens",
                "prompt-tokens",
                "total-tokens"
              ],
              "uiOrder": 0,
              "title": "Usage",
              "format": "object"
            }
          },
          "required": [],
          "title": "Output Metadata",
          "uiOrder": 1,
          "format": "object"
        }
      },
      "required": [
        "data"
      ],
      "format": "object"
    }
  }
}
