---
title: "Instill Model"
lang: "en-US"
draft: false
description: "Learn about how to set up a VDP Instill Model component https://github.com/instill-ai/instill-core"
---

The Instill Model component is an AI component that allows users to connect the AI models served on the Instill Model Platform.
It can carry out the following tasks:
- [Embedding](#embedding)
- [Chat](#chat)



## Release Stage

`Alpha`



## Configuration

The component definition and tasks are defined in the [definition.json](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/ai/instill/v0/config/definition.json) and [tasks.json](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/ai/instill/v0/config/tasks.json) files respectively.






## Supported Tasks

### Embedding

This task refers to the process of generating vector embeddings from input data, which can be text or images. This transformation converts the data into a dense, fixed-length numerical representation that captures the essential features of the original input. These embeddings are typically used in machine learning tasks to represent complex data in a more structured, simplified form.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_EMBEDDING` |
| [Data](#embedding-data) (required) | `data` | object | Input data. |
| [Parameter](#embedding-parameter) | `parameter` | object | Input parameter. |
</div>


<details>
<summary> Input Objects in Embedding</summary>

<h4 id="embedding-data">Data</h4>

Input data.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| [Embeddings](#embedding-embeddings) | `embeddings` | array | List of input data to be embedded.  |
| Model | `model` | string | The model to be used for generating embeddings. It should be `namespace/model-name/version`. i.e. `abrc/yolov7-stomata/v0.1.0`. You can see the version from the Versions tab of Model page.  |
</div>
<h4 id="embedding-parameter">Parameter</h4>

Input parameter.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Dimensions | `dimensions` | integer | Number of dimensions in the output embedding vectors.  |
| Data Format | `format` | string | The data format of the embeddings. Defaults to float.  <br/><details><summary><strong>Enum values</strong></summary><ul><li>`float`</li><li>`base64`</li></ul></details>  |
| Input Type | `input-type` | string | The type of input data to be embedded (e.g., query, document).  |
| Truncate | `truncate` | string | How to handle inputs longer than the max token length. Defaults to 'End'.  <br/><details><summary><strong>Enum values</strong></summary><ul><li>`None`</li><li>`End`</li><li>`Start`</li></ul></details>  |
</div>
</details>

<details>
<summary>The <code>embeddings</code> Object </summary>

<h4 id="embedding-embeddings">Embeddings</h4>

`embeddings` must fulfill one of the following schemas:

<h5 id="embedding-text"><code>Text</code></h5>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Text Content | `text` | string |  When the input is text, the raw text is tokenized and processed into a dense, fixed-length vector that captures semantic information such as word meanings and relationships. These text embeddings enable tasks like sentiment analysis, search, or classification.  |
| Text | `type` | string |  Must be `"text"`   |
</div>

<h5 id="embedding-image-url"><code>Image URL</code></h5>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Image URL | `image-url` | string |  When the input is an image from a URL, the image is first fetched from the URL and then decoded into its original format. It is then processed into a fixed-length vector representing essential visual features like shapes and colors. These image embeddings are useful for tasks like image classification or similarity search, providing structured numerical data for complex visual inputs.  |
| Image URL | `type` | string |  Must be `"image-url"`   |
</div>

<h5 id="embedding-image-base64"><code>Image Base64</code></h5>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Image File | `image-base64` | string |  When the input is an image in base64 format, the base64-encoded data is first decoded into its original image form. The image is then processed and transformed into a dense, fixed-length numerical vector, capturing key visual features like shapes, colors, or textures.  |
| Image File | `type` | string |  Must be `"image-base64"`   |
</div>
</details>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| [Data](#embedding-data) | `data` | object | Output data. |
</div>

<details>
<summary> Output Objects in Embedding</summary>

<h4 id="embedding-data">Data</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| [Embeddings](#embedding-embeddings) | `embeddings` | array | List of generated embeddings. |
</div>

<h4 id="embedding-embeddings">Embeddings</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Created | `created` | integer | The Unix timestamp (in seconds) of when the embedding was created. |
| Index | `index` | integer | The index of the embedding vector in the array. |
| Embedding Vector | `vector` | array | The embedding vector. |
</div>
</details>

### Chat

This task involves generating contextually relevant text responses based on input data, such as user queries or prompts. The generated responses include metadata like token usage, which can help track and calculate the cost of the operation. This metadata can also be useful for performance monitoring and analysis.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_CHAT` |
| [Chat Data](#chat-chat-data) (required) | `data` | object | The data that will be passed to the chat model. This typically includes the messages exchanged between the user and the assistant, alongside any additional information to guide the conversation. |
| [Input Parameter](#chat-input-parameter) | `parameter` | object | The parameters used to control how the model generates responses. These include settings for token limits, randomness, and the number of response choices. |
</div>


<details>
<summary> Input Objects in Chat</summary>

<h4 id="chat-chat-data">Chat Data</h4>

The data that will be passed to the chat model. This typically includes the messages exchanged between the user and the assistant, alongside any additional information to guide the conversation.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| [Chat Messages](#chat-chat-messages) | `messages` | array | A collection of individual messages exchanged during the chat session. Each message includes content and other attributes like role and optional participant name.  |
</div>
<h4 id="chat-chat-messages">Chat Messages</h4>

A collection of individual messages exchanged during the chat session. Each message includes content and other attributes like role and optional participant name.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| [Content](#chat-content) | `content` | array | The actual content of the message. It can be a text message, an image URL, or a base64 encoded image.  |
| Name | `name` | string | An optional name for the participant sending the message. This can be used to distinguish between different users or assistants if there are multiple participants with the same role.  |
| Role | `role` | string | Indicates the role of the message sender, such as 'user', 'assistant', or 'system'. This helps the model understand the context in which the message was sent.  <br/><details><summary><strong>Enum values</strong></summary><ul><li>`system`</li><li>`user`</li><li>`assistant`</li></ul></details>  |
</div>
<h4 id="chat-input-parameter">Input Parameter</h4>

The parameters used to control how the model generates responses. These include settings for token limits, randomness, and the number of response choices.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Max New Tokens | `max-tokens` | integer | Defines the maximum number of tokens that the model can generate in response to a given input.  |
| Number of Choices | `n` | integer | Determines how many different response options the model should generate for a single input. This allows the user to choose between multiple potential responses.  |
| Seed | `seed` | integer | A random seed used for controlling the randomness of the model's output. Setting a seed can make the model's responses deterministic and reproducible.  |
| Stream | `stream` | boolean | If set to true, the model will send tokens as they are generated in a streaming manner, rather than waiting for the entire response to be ready.  |
| Temperature | `temperature` | number | A parameter that controls how random or creative the model's responses are. Higher values make the responses more diverse and creative, while lower values make them more focused and deterministic. The default value is 0.7.  |
| Top P | `top-p` | number | An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.  |
</div>
</details>



<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| [Output Data](#chat-output-data) | `data` | object | This section defines the structure of the output data returned by the chat task. The output includes chat completion choices generated by the model along with metadata such as the reason for finishing, message content, and creation timestamp. Each generated response is structured as a choice that includes details about the model’s reasoning for ending the response generation, the message content, and the role of the message's author. |
| [Output Metadata](#chat-output-metadata) (optional) | `metadata` | object | This section provides metadata about the task completion, including statistics on the usage of tokens. The metadata helps track how many tokens were used in generating the response and how many tokens were included in the input prompt. |
</div>

<details>
<summary> Output Objects in Chat</summary>

<h4 id="chat-output-data">Output Data</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| [Choices](#chat-choices) | `choices` | array | This is a list of all the possible chat completion choices generated by the model for a given input. Each choice represents a potential response the model can provide based on the input message. |
</div>

<h4 id="chat-choices">Choices</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Created | `created` | integer | The Unix timestamp (in seconds) indicating when the chat completion was generated. This timestamp can be used to track when the response was created. |
| Finish Reason | `finish-reason` | string | The reason why the model stopped generating tokens for this particular response. It could indicate that the model finished the response naturally, or there could be another stopping criterion. |
| Index | `index` | integer | The index or position of this choice in the list of possible responses. This helps to identify which option is being referred to in a set of choices. |
| [Message](#chat-message) | `message` | object | The chat message generated by the model as a response to the input. This includes the text content and the role of the message sender (e.g., user, system, assistant). |
</div>

<h4 id="chat-message">Message</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Content | `content` | string | The actual text content of the generated message. This is what the model suggests as the response based on the given input. |
| Role | `role` | string | The role of the entity that generated the message, such as 'system, 'user', or 'assistant'. This allows differentiation between who is sending the message. |
</div>

<h4 id="chat-output-metadata">Output Metadata</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| [Usage](#chat-usage) | `usage` | object | Provides information about the number of tokens involved in the request and the completion process. It includes prompt tokens, completion tokens, and the total number of tokens used. |
</div>

<h4 id="chat-usage">Usage</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Completion Tokens | `completion-tokens` | integer | The number of tokens generated in the response. This indicates how many tokens were used in the model's reply. |
| Prompt Tokens | `prompt-tokens` | integer | The number of tokens that were in the input prompt. This counts how many tokens were consumed in processing the initial user query or input. |
| Total Tokens | `total-tokens` | integer | The total number of tokens used in the entire request, which is the sum of prompt tokens and completion tokens. |
</div>
</details>


