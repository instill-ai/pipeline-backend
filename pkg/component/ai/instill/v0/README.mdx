---
title: "Instill Model"
lang: "en-US"
draft: false
description: "Learn about how to set up a VDP Instill Model component https://github.com/instill-ai/instill-core"
---

The Instill Model component is an AI component that allows users to connect the AI models served on the Instill Model Platform.
It can carry out the following tasks:
- [Chat](#chat)
- [Classification](#classification)
- [Detection](#detection)
- [Embedding](#embedding)
- [Instance Segmentation](#instance-segmentation)
- [Keypoint](#keypoint)
- [OCR](#ocr)
- [Semantic Segmentation](#semantic-segmentation)
- [Text Generation](#text-generation)
- [Text Generation Chat](#text-generation-chat)
- [Text to Image](#text-to-image)
- [Visual Question Answering](#visual-question-answering)



## Release Stage

`Alpha`



## Configuration

The component definition and tasks are defined in the [definition.yaml](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/ai/instill/v0/config/definition.yaml) and [tasks.yaml](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/ai/instill/v0/config/tasks.yaml) files respectively.







## Supported Tasks

### Chat

Generate texts from input text prompts and chat history.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_CHAT` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Prompt (required) | `prompt` | string | The prompt text. |
| System Message | `system-message` | string | The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model’s behavior is using a generic message as "You are a helpful assistant.". |
| Prompt Images | `prompt-images` | array[string] | The prompt images. |
| [Chat History](#chat-chat-history) | `chat-history` | array[object] | Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: : \{"role": "The message role, i.e. 'system', 'user' or 'assistant'", "content": "message content"\}. |
| Seed | `seed` | integer | The seed. |
| Temperature | `temperature` | number | The temperature for sampling. |
| Max New Tokens | `max-new-tokens` | integer | The maximum number of tokens for model to generate. |
</div>


<details>
<summary> Input Objects in Chat</summary>

<h4 id="chat-chat-history">Chat History</h4>

Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: : \{"role": "The message role, i.e. 'system', 'user' or 'assistant'", "content": "message content"\}.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Content](#chat-content) | `content` | array | The message content.  |
| Role | `role` | string | The message role, i.e. 'system', 'user' or 'assistant'.  |
</div>
<h4 id="chat-content">Content</h4>

The message content.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Image URL](#chat-image-url) | `image-url` | object | The image URL  |
| Text | `text` | string | The text content.  |
| Type | `type` | string | The type of the content part.  <br/><details><summary><strong>Enum values</strong></summary><ul><li>`text`</li><li>`image-url`</li></ul></details>  |
</div>
<h4 id="chat-image-url">Image URL</h4>

The image URL

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| URL | `url` | string | Either a URL of the image or the base64 encoded image data.  |
</div>
</details>



<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Text | `text` | string | Text. |
</div>


### Classification

Classify images into predefined categories.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_CLASSIFICATION` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Category | `category` | string | The predicted category of the input. |
| Score | `score` | number | The confidence score of the predicted category of the input. |
</div>


### Detection

Detect and localize multiple objects in images.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_DETECTION` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| [Objects](#detection-objects) | `objects` | array[object] | A list of detected objects. |
</div>

<details>
<summary> Output Objects in Detection</summary>

<h4 id="detection-objects">Objects</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Bounding box](#detection-bounding-box) | `bounding-box` | object | The detected bounding box in (left, top, width, height) format. |
| Category | `category` | string | The predicted category of the bounding box. |
| Score | `score` | number | The confidence score of the predicted category of the bounding box. |
</div>

<h4 id="detection-bounding-box">Bounding Box</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| Height | `height` | number | Bounding box height value |
| Left | `left` | number | Bounding box left x-axis value |
| Top | `top` | number | Bounding box top y-axis value |
| Width | `width` | number | Bounding box width value |
</div>
</details>


### Embedding

This task refers to the process of generating vector embeddings from input data, which can be text or images. This transformation converts the data into a dense, fixed-length numerical representation that captures the essential features of the original input. These embeddings are typically used in machine learning tasks to represent complex data in a more structured, simplified form.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_EMBEDDING` |
| [Data](#embedding-data) (required) | `data` | object | Input data. |
| [Parameter](#embedding-parameter) | `parameter` | object | Input parameter. |
</div>


<details>
<summary> Input Objects in Embedding</summary>

<h4 id="embedding-data">Data</h4>

Input data.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Embeddings](#embedding-embeddings) | `embeddings` | array | List of input data to be embedded.  |
| Model | `model` | string | The model to be used for generating embeddings. It should be `namespace/model-name/version`. i.e. `abrc/yolov7-stomata/v0.1.0`. You can see the version from the Versions tab of Model page.  |
</div>
<h4 id="embedding-parameter">Parameter</h4>

Input parameter.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| Dimensions | `dimensions` | integer | Number of dimensions in the output embedding vectors.  |
| Data Format | `format` | string | The data format of the embeddings. Defaults to float.  <br/><details><summary><strong>Enum values</strong></summary><ul><li>`float`</li><li>`base64`</li></ul></details>  |
| Input Type | `input-type` | string | The type of input data to be embedded (e.g., query, document).  |
| Truncate | `truncate` | string | How to handle inputs longer than the max token length. Defaults to 'End'.  <br/><details><summary><strong>Enum values</strong></summary><ul><li>`None`</li><li>`End`</li><li>`Start`</li></ul></details>  |
</div>
</details>

<details>
<summary>The <code>embeddings</code> Object </summary>

<h4 id="embedding-embeddings">Embeddings</h4>

`embeddings` must fulfill one of the following schemas:

<h5 id="embedding-text"><code>Text</code></h5>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| Text Content | `text` | string |  When the input is text, the raw text is tokenized and processed into a dense, fixed-length vector that captures semantic information such as word meanings and relationships. These text embeddings enable tasks like sentiment analysis, search, or classification.  |
| Text | `type` | string |  Must be `"text"`   |
</div>

<h5 id="embedding-image-url"><code>Image URL</code></h5>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| Image URL | `image-url` | string |  When the input is an image from a URL, the image is first fetched from the URL and then decoded into its original format. It is then processed into a fixed-length vector representing essential visual features like shapes and colors. These image embeddings are useful for tasks like image classification or similarity search, providing structured numerical data for complex visual inputs.  |
| Image URL | `type` | string |  Must be `"image-url"`   |
</div>

<h5 id="embedding-image-base64"><code>Image Base64</code></h5>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| Image File | `image-base64` | string |  When the input is an image in base64 format, the base64-encoded data is first decoded into its original image form. The image is then processed and transformed into a dense, fixed-length numerical vector, capturing key visual features like shapes, colors, or textures.  |
| Image File | `type` | string |  Must be `"image-base64"`   |
</div>
</details>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| [Data](#embedding-data) | `data` | object | Output data. |
</div>

<details>
<summary> Output Objects in Embedding</summary>

<h4 id="embedding-data">Data</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Embeddings](#embedding-embeddings) | `embeddings` | array | List of generated embeddings. |
</div>

<h4 id="embedding-embeddings">Embeddings</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| Created | `created` | integer | The Unix timestamp (in seconds) of when the embedding was created. |
| Index | `index` | integer | The index of the embedding vector in the array. |
| Embedding Vector | `vector` | array | The embedding vector. |
</div>
</details>


### Instance Segmentation

Detect, localize and delineate multiple objects in images.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_INSTANCE_SEGMENTATION` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| [Objects](#instance-segmentation-objects) | `objects` | array[object] | A list of detected instance bounding boxes. |
</div>

<details>
<summary> Output Objects in Instance Segmentation</summary>

<h4 id="instance-segmentation-objects">Objects</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Bounding Box](#instance-segmentation-bounding-box) | `bounding-box` | object | The detected bounding box in (left, top, width, height) format. |
| Category | `category` | string | The predicted category of the bounding box. |
| RLE | `rle` | string | Run Length Encoding (RLE) of instance mask within the bounding box. |
| Score | `score` | number | The confidence score of the predicted instance object. |
</div>

<h4 id="instance-segmentation-bounding-box">Bounding Box</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| Height | `height` | number | Bounding box height value |
| Left | `left` | number | Bounding box left x-axis value |
| Top | `top` | number | Bounding box top y-axis value |
| Width | `width` | number | Bounding box width value |
</div>
</details>


### Keypoint

Detect and localize multiple keypoints of objects in images.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_KEYPOINT` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| [Objects](#keypoint-objects) | `objects` | array[object] | A list of keypoint objects, a keypoint object includes all the pre-defined keypoints of a detected object. |
</div>

<details>
<summary> Output Objects in Keypoint</summary>

<h4 id="keypoint-objects">Objects</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Bounding Box](#keypoint-bounding-box) | `bounding-box` | object | The detected bounding box in (left, top, width, height) format. |
| [Keypoints](#keypoint-keypoints) | `keypoints` | array | A keypoint group is composed of a list of pre-defined keypoints of a detected object. |
| Score | `score` | number | The confidence score of the predicted object. |
</div>

<h4 id="keypoint-keypoints">Keypoints</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| Visibility Score | `v` | number | visibility score of the keypoint. |
| X Coordinate | `x` | number | x coordinate of the keypoint. |
| Y Coordinate | `y` | number | y coordinate of the keypoint. |
</div>

<h4 id="keypoint-bounding-box">Bounding Box</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| Height | `height` | number | Bounding box height value |
| Left | `left` | number | Bounding box left x-axis value |
| Top | `top` | number | Bounding box top y-axis value |
| Width | `width` | number | Bounding box width value |
</div>
</details>


### OCR

Detect and recognize text in images.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_OCR` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| [Objects](#ocr-objects) | `objects` | array[object] | A list of detected bounding boxes. |
</div>

<details>
<summary> Output Objects in OCR</summary>

<h4 id="ocr-objects">Objects</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Bounding Box](#ocr-bounding-box) | `bounding-box` | object | The detected bounding box in (left, top, width, height) format. |
| Score | `score` | number | The confidence score of the predicted object. |
| Text | `text` | string | Text string recognised per bounding box. |
</div>

<h4 id="ocr-bounding-box">Bounding Box</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| Height | `height` | number | Bounding box height value |
| Left | `left` | number | Bounding box left x-axis value |
| Top | `top` | number | Bounding box top y-axis value |
| Width | `width` | number | Bounding box width value |
</div>
</details>


### Semantic Segmentation

Classify image pixels into predefined categories.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_SEMANTIC_SEGMENTATION` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| [Stuffs](#semantic-segmentation-stuffs) | `stuffs` | array[object] | A list of RLE binary masks. |
</div>

<details>
<summary> Output Objects in Semantic Segmentation</summary>

<h4 id="semantic-segmentation-stuffs">Stuffs</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| Category | `category` | string | Category text string corresponding to each stuff mask. |
| RLE | `rle` | string | Run Length Encoding (RLE) of each stuff mask within the image. |
</div>
</details>


### Text Generation

Generate texts from input text prompts.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_TEXT_GENERATION` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Prompt (required) | `prompt` | string | The prompt text. |
| System Message | `system-message` | string | The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model’s behavior is using a generic message as "You are a helpful assistant.". |
| Seed | `seed` | integer | The seed. |
| Temperature | `temperature` | number | The temperature for sampling. |
| Max New Tokens | `max-new-tokens` | integer | The maximum number of tokens for model to generate. |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Text | `text` | string | Text. |
</div>


### Text Generation Chat

Generate texts from input text prompts and chat history.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_TEXT_GENERATION_CHAT` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Prompt (required) | `prompt` | string | The prompt text. |
| System Message | `system-message` | string | The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model’s behavior is using a generic message as "You are a helpful assistant.". |
| Prompt Images | `prompt-images` | array[string] | The prompt images. |
| [Chat History](#text-generation-chat-chat-history) | `chat-history` | array[object] | Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: : \{"role": "The message role, i.e. 'system', 'user' or 'assistant'", "content": "message content"\}. |
| Seed | `seed` | integer | The seed. |
| Temperature | `temperature` | number | The temperature for sampling. |
| Max New Tokens | `max-new-tokens` | integer | The maximum number of tokens for model to generate. |
</div>


<details>
<summary> Input Objects in Text Generation Chat</summary>

<h4 id="text-generation-chat-chat-history">Chat History</h4>

Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: : \{"role": "The message role, i.e. 'system', 'user' or 'assistant'", "content": "message content"\}.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Content](#text-generation-chat-content) | `content` | array | The message content.  |
| Role | `role` | string | The message role, i.e. 'system', 'user' or 'assistant'.  |
</div>
<h4 id="text-generation-chat-content">Content</h4>

The message content.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Image URL](#text-generation-chat-image-url) | `image-url` | object | The image URL  |
| Text | `text` | string | The text content.  |
| Type | `type` | string | The type of the content part.  <br/><details><summary><strong>Enum values</strong></summary><ul><li>`text`</li><li>`image-url`</li></ul></details>  |
</div>
<h4 id="text-generation-chat-image-url">Image URL</h4>

The image URL

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| URL | `url` | string | Either a URL of the image or the base64 encoded image data.  |
</div>
</details>



<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Text | `text` | string | Text. |
</div>


### Text to Image

Generate images from input text prompts.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_TEXT_TO_IMAGE` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Prompt (required) | `prompt` | string | The prompt text. |
| Samples | `samples` | integer | The number of generated samples, default is 1. |
| Seed | `seed` | integer | The seed, default is 0. |
| Aspect Ratio | `negative-prompt` | string | Keywords of what you do not wish to see in the output image. |
| Aspect Ratio | `aspect-ratio` | string | Controls the aspect ratio of the generated image. Defaults to 1:1. <br/><details><summary><strong>Enum values</strong></summary><ul><li>`16:9`</li><li>`1:1`</li><li>`21:9`</li><li>`2:3`</li><li>`3:2`</li><li>`4:5`</li><li>`5:4`</li><li>`9:16`</li><li>`9:21`</li></ul></details>  |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Images | `images` | array[image/jpeg] | Images. |
</div>


### Visual Question Answering

Answer questions based on a prompt and an image.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_VISUAL_QUESTION_ANSWERING` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Prompt (required) | `prompt` | string | The prompt text. |
| System Message | `system-message` | string | The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model’s behavior is using a generic message as "You are a helpful assistant.". |
| Prompt Images | `prompt-images` | array[string] | The prompt images. |
| [Chat History](#visual-question-answering-chat-history) | `chat-history` | array[object] | Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: : \{"role": "The message role, i.e. 'system', 'user' or 'assistant'", "content": "message content"\}. |
| Seed | `seed` | integer | The seed. |
| Temperature | `temperature` | number | The temperature for sampling. |
| Max New Tokens | `max-new-tokens` | integer | The maximum number of tokens for model to generate. |
</div>


<details>
<summary> Input Objects in Visual Question Answering</summary>

<h4 id="visual-question-answering-chat-history">Chat History</h4>

Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: : \{"role": "The message role, i.e. 'system', 'user' or 'assistant'", "content": "message content"\}.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Content](#visual-question-answering-content) | `content` | array | The message content.  |
| Role | `role` | string | The message role, i.e. 'system', 'user' or 'assistant'.  |
</div>
<h4 id="visual-question-answering-content">Content</h4>

The message content.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| [Image URL](#visual-question-answering-image-url) | `image-url` | object | The image URL  |
| Text | `text` | string | The text content.  |
| Type | `type` | string | The type of the content part.  <br/><details><summary><strong>Enum values</strong></summary><ul><li>`text`</li><li>`image-url`</li></ul></details>  |
</div>
<h4 id="visual-question-answering-image-url">Image URL</h4>

The image URL

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Format | Note |
| :--- | :--- | :--- | :--- |
| URL | `url` | string | Either a URL of the image or the base64 encoded image data.  |
</div>
</details>



<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Format | Description |
| :--- | :--- | :--- | :--- |
| Text | `text` | string | Text. |
</div>



