{
  "TASK_EMBEDDING": {
    "title": "Embedding",
    "instillShortDescription": "This task refers to the process of generating vector embeddings from input data, which can be text or images. This transformation converts the data into a dense, fixed-length numerical representation that captures the essential features of the original input. These embeddings are typically used in machine learning tasks to represent complex data in a more structured, simplified form.",
    "input": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Embedding Input",
      "description": "Input schema of the embedding task.",
      "instillShortDescription": "Input schema of the embedding task.",
      "type": "object",
      "properties": {
        "data": {
          "description": "Input data.",
          "instillShortDescription": "Input data.",
          "type": "object",
          "properties": {
            "model": {
              "description": "The model to be used for generating embeddings. It should be `namespace/model-name/version`. i.e. `abrc/yolov7-stomata/v0.1.0`. You can see the version from the Versions tab of Model page.",
              "instillShortDescription": "The model to be used.",
              "instillAcceptFormats": [
                "string"
              ],
              "instillUIOrder": 0,
              "title": "Model",
              "type": "string"
            },
            "embeddings": {
              "title": "Embeddings",
              "type": "array",
              "items": {
                "type": "object",
                "oneOf": [
                  {
                    "type": "object",
                    "properties": {
                      "text": {
                        "title": "Text Content",
                        "description": "When the input is text, the raw text is tokenized and processed into a dense, fixed-length vector that captures semantic information such as word meanings and relationships. These text embeddings enable tasks like sentiment analysis, search, or classification.",
                        "instillShortDescription": "Text content.",
                        "instillAcceptFormats": [
                          "string"
                        ],
                        "type": "string",
                        "instillUIOrder": 1
                      },
                      "type": {
                        "title": "Text",
                        "description": "Text input content type.",
                        "instillShortDescription": "Text input content type.",
                        "instillAcceptFormats": [
                          "string"
                        ],
                        "type": "string",
                        "const": "text",
                        "instillUIOrder": 0
                      }
                    },
                    "title": "Text",
                    "required": [
                      "text",
                      "type"
                    ]
                  },
                  {
                    "type": "object",
                    "properties": {
                      "image-url": {
                        "title": "Image URL",
                        "description": "When the input is an image from a URL, the image is first fetched from the URL and then decoded into its original format. It is then processed into a fixed-length vector representing essential visual features like shapes and colors. These image embeddings are useful for tasks like image classification or similarity search, providing structured numerical data for complex visual inputs.",
                        "instillShortDescription": "Image content URL.",
                        "instillAcceptFormats": [
                          "string"
                        ],
                        "type": "string",
                        "instillUIOrder": 1
                      },
                      "type": {
                        "title": "Image URL",
                        "description": "Image URL input content type",
                        "instillShortDescription": "Image URL input content type",
                        "instillAcceptFormats": [
                          "string"
                        ],
                        "type": "string",
                        "const": "image-url",
                        "instillUIOrder": 0
                      }
                    },
                    "title": "Image URL",
                    "required": [
                      "image-url",
                      "type"
                    ]
                  },
                  {
                    "type": "object",
                    "properties": {
                      "image-base64": {
                        "title": "Image File",
                        "description": "When the input is an image in base64 format, the base64-encoded data is first decoded into its original image form. The image is then processed and transformed into a dense, fixed-length numerical vector, capturing key visual features like shapes, colors, or textures.",
                        "instillShortDescription": "Image file input.",
                        "instillAcceptFormats": [
                          "image/*"
                        ],
                        "type": "string",
                        "instillUIOrder": 1
                      },
                      "type": {
                        "title": "Image File",
                        "description": "Image file input content type.",
                        "instillShortDescription": "Image file input content type.",
                        "instillAcceptFormats": [
                          "string"
                        ],
                        "type": "string",
                        "const": "image-base64",
                        "instillUIOrder": 0
                      }
                    },
                    "title": "Image Base64",
                    "required": [
                      "image-base64",
                      "type"
                    ]
                  }
                ],
                "title": "Embedding",
                "description": "Input data to be embedded.",
                "instillUIOrder": 0,
                "required": [
                  "type"
                ]
              },
              "description": "List of input data to be embedded.",
              "instillUIOrder": 1
            }
          },
          "required": [
            "model",
            "embeddings"
          ],
          "instillUIOrder": 0,
          "title": "Data"
        },
        "parameter": {
          "description": "Input parameter.",
          "instillShortDescription": "Input parameter.",
          "type": "object",
          "properties": {
            "format": {
              "title": "Data Format",
              "type": "string",
              "description": "The data format of the embeddings. Defaults to float.",
              "instillShortDescription": "Data format",
              "instillAcceptFormats": [
                "string"
              ],
              "enum": [
                "float",
                "base64"
              ],
              "default": "float",
              "instillUIOrder": 0
            },
            "dimensions": {
              "title": "Dimensions",
              "type": "integer",
              "description": "Number of dimensions in the output embedding vectors.",
              "instillShortDescription": "Number of dimensions",
              "instillAcceptFormats": [
                "integer"
              ],
              "default": 512,
              "instillUIOrder": 1
            },
            "input-type": {
              "title": "Input Type",
              "type": "string",
              "description": "The type of input data to be embedded (e.g., query, document).",
              "instillShortDescription": "Type of input data",
              "instillAcceptFormats": [
                "string"
              ],
              "instillUIOrder": 2
            },
            "truncate": {
              "title": "Truncate",
              "type": "string",
              "description": "How to handle inputs longer than the max token length. Defaults to 'End'.",
              "instillShortDescription": "Truncation handling",
              "instillAcceptFormats": [
                "string"
              ],
              "enum": [
                "None",
                "End",
                "Start"
              ],
              "default": "End",
              "instillUIOrder": 3
            }
          },
          "title": "Parameter",
          "instillUIOrder": 1,
          "required": []
        }
      },
      "required": [
        "data"
      ]
    },
    "output": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Embedding Output",
      "description": "Output schema of the embedding task.",
      "instillShortDescription": "Output schema of the embedding task.",
      "type": "object",
      "properties": {
        "data": {
          "description": "Output data.",
          "instillShortDescription": "Output data.",
          "type": "object",
          "properties": {
            "embeddings": {
              "title": "Embeddings",
              "type": "array",
              "description": "List of generated embeddings.",
              "instillShortDescription": "List of embeddings.",
              "instillFormat": "array",
              "items": {
                "type": "object",
                "properties": {
                  "index": {
                    "title": "Index",
                    "type": "integer",
                    "description": "The index of the embedding vector in the array.",
                    "instillShortDescription": "Index in the array",
                    "instillFormat": "integer",
                    "instillUIOrder": 0
                  },
                  "vector": {
                    "title": "Embedding Vector",
                    "type": "array",
                    "description": "The embedding vector.",
                    "instillShortDescription": "Embedding vector.",
                    "instillFormat": "array",
                    "items": {
                      "type": "number"
                    },
                    "instillUIOrder": 1
                  },
                  "created": {
                    "title": "Created",
                    "type": "integer",
                    "description": "The Unix timestamp (in seconds) of when the embedding was created.",
                    "instillShortDescription": "Timestamp of creation",
                    "instillFormat": "integer",
                    "instillUIOrder": 2
                  }
                },
                "required": [
                  "index",
                  "vector",
                  "created"
                ]
              },
              "instillUIOrder": 0
            }
          },
          "required": [
            "embeddings"
          ],
          "instillUIOrder": 0,
          "title": "Data"
        }
      },
      "required": [
        "data"
      ]
    }
  },
  "TASK_CHAT": {
    "title": "Chat",
    "instillShortDescription": "This task involves generating contextually relevant text responses based on input data, such as user queries or prompts. The generated responses include metadata like token usage, which can help track and calculate the cost of the operation. This metadata can also be useful for performance monitoring and analysis.",
    "input": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Chat Input",
      "description": "This is the schema for the input required to perform the chat task. It defines the structure of the data that must be provided, including the types of messages, roles, and optional parameters that guide the model's response generation.",
      "instillShortDescription": "Input schema for the chat task, defining data format and necessary attributes.",
      "type": "object",
      "properties": {
        "data": {
          "title": "Chat Data",
          "description": "The data that will be passed to the chat model. This typically includes the messages exchanged between the user and the assistant, alongside any additional information to guide the conversation.",
          "instillShortDescription": "The main input data for the chat task, such as the conversation content.",
          "type": "object",
          "properties": {
            "model": {
              "description": "The model to be used for generating chat responses. It should be `namespace/model-name/version`. i.e. `abrc/gpt-3/v0.1.0`. You can see the version from the Versions tab of Model page.",
              "instillShortDescription": "The model to be used for generating chat responses.",
              "instillUIOrder": 0,
              "instillAcceptFormats": [
                "string"
              ],
              "title": "Model Name",
              "type": "string"
            },
            "messages": {
              "description": "A collection of individual messages exchanged during the chat session. Each message includes content and other attributes like role and optional participant name.",
              "instillShortDescription": "The messages that make up the conversation. Each message has content and a role, such as 'user', 'assistant', or 'system'.",
              "title": "Chat Messages",
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "content": {
                    "description": "The actual content of the message. It can be a text message, an image URL, or a base64 encoded image.",
                    "instillShortDescription": "The main content of the message, which can be text or image-based, and defines what the user or assistant is saying.",
                    "title": "Content",
                    "type": "array",
                    "items": {
                      "type": "object",
                      "oneOf": [
                        {
                          "type": "object",
                          "properties": {
                            "text": {
                              "title": "Text Message",
                              "description": "A text-based message, which is the most common format for chat communication.",
                              "instillShortDescription": "Plain text content of the message.",
                              "instillAcceptFormats": [
                                "string"
                              ],
                              "type": "string",
                              "instillUIOrder": 1
                            },
                            "type": {
                              "title": "Text",
                              "description": "Type of the message content. In this case, it is text.",
                              "instillShortDescription": "Type of the message content. In this case, it is text.",
                              "instillAcceptFormats": [
                                "string"
                              ],
                              "type": "string",
                              "const": "text",
                              "instillUIOrder": 0
                            }
                          },
                          "required": [
                            "text",
                            "type"
                          ],
                          "title": "Text"
                        },
                        {
                          "type": "object",
                          "properties": {
                            "image-url": {
                              "title": "Image URL",
                              "description": "A URL that links to an image that is being shared in the chat.",
                              "instillShortDescription": "A message that shares an image through a URL link.",
                              "instillAcceptFormats": [
                                "string"
                              ],
                              "type": "string",
                              "instillUIOrder": 1
                            },
                            "type": {
                              "title": "Image URL",
                              "description": "Type of the message content. In this case, it is an image URL.",
                              "instillShortDescription": "Type of the message content. In this case, it is an image URL.",
                              "instillAcceptFormats": [
                                "string"
                              ],
                              "type": "string",
                              "const": "image-url",
                              "instillUIOrder": 0
                            }
                          },
                          "required": [
                            "image-url",
                            "type"
                          ],
                          "title": "Image URL"
                        },
                        {
                          "type": "object",
                          "properties": {
                            "image-base64": {
                              "title": "Image Base64",
                              "description": "An image encoded as a base64 string, allowing for the direct transfer of image data in the message.",
                              "instillShortDescription": "A base64-encoded image message for directly embedding image content.",
                              "instillAcceptFormats": [
                                "image/*"
                              ],
                              "type": "string",
                              "instillUIOrder": 1
                            },
                            "type": {
                              "title": "Image File",
                              "description": "Type of the message content. In this case, it is an image file.",
                              "instillShortDescription": "Type of the message content. In this case, it is an image file.",
                              "instillAcceptFormats": [
                                "string"
                              ],
                              "type": "string",
                              "const": "image-base64",
                              "instillUIOrder": 0
                            }
                          },
                          "required": [
                            "image-base64",
                            "type"
                          ],
                          "title": "Image Base64"
                        }
                      ],
                      "required": []
                    },
                    "instillUIOrder": 0
                  },
                  "role": {
                    "description": "Indicates the role of the message sender, such as 'user', 'assistant', or 'system'. This helps the model understand the context in which the message was sent.",
                    "instillShortDescription": "The role of the message sender, such as 'user', 'assistant', or 'system'.",
                    "instillAcceptFormats": [
                      "string"
                    ],
                    "title": "Role",
                    "type": "string",
                    "enum": [
                      "system",
                      "user",
                      "assistant"
                    ],
                    "instillUIOrder": 1
                  },
                  "name": {
                    "description": "An optional name for the participant sending the message. This can be used to distinguish between different users or assistants if there are multiple participants with the same role.",
                    "instillShortDescription": "An optional name for the participant sending the message.",
                    "instillAcceptFormats": [
                      "string"
                    ],
                    "title": "Name",
                    "type": "string",
                    "instillUIOrder": 2
                  }
                },
                "required": [
                  "content",
                  "role"
                ]
              },
              "instillUIOrder": 1
            }
          },
          "required": [
            "messages"
          ],
          "instillUIOrder": 0
        },
        "parameter": {
          "description": "The parameters used to control how the model generates responses. These include settings for token limits, randomness, and the number of response choices.",
          "instillShortDescription": "Parameters that control the model's response generation, such as token limits and randomness settings.",
          "type": "object",
          "properties": {
            "max-tokens": {
              "title": "Max New Tokens",
              "type": "integer",
              "description": "Defines the maximum number of tokens that the model can generate in response to a given input.",
              "instillShortDescription": "The maximum number of tokens the model can generate in response to a single input message.",
              "instillAcceptFormats": [
                "integer"
              ],
              "default": 50,
              "instillUIOrder": 0
            },
            "seed": {
              "title": "Seed",
              "type": "integer",
              "description": "A random seed used for controlling the randomness of the model's output. Setting a seed can make the model's responses deterministic and reproducible.",
              "instillShortDescription": "A random seed used to control the model's output randomness.",
              "instillAcceptFormats": [
                "integer"
              ],
              "default": 0,
              "instillUIOrder": 1
            },
            "n": {
              "title": "Number of Choices",
              "type": "integer",
              "description": "Determines how many different response options the model should generate for a single input. This allows the user to choose between multiple potential responses.",
              "instillShortDescription": "The number of response choices the model should generate for a single input.",
              "instillAcceptFormats": [
                "integer"
              ],
              "default": 1,
              "instillUIOrder": 2
            },
            "temperature": {
              "title": "Temperature",
              "type": "number",
              "description": "A parameter that controls how random or creative the model's responses are. Higher values make the responses more diverse and creative, while lower values make them more focused and deterministic. The default value is 0.7.",
              "instillShortDescription": "A parameter that controls the randomness of the model's responses. Higher values make the responses more diverse and creative.",
              "instillAcceptFormats": [
                "number"
              ],
              "default": 0.7,
              "instillUIOrder": 3
            },
            "top-p": {
              "title": "Top P",
              "type": "number",
              "description": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.",
              "instillShortDescription": "An alternative to temperature sampling, where the model considers the top_p probability mass of tokens.",
              "instillAcceptFormats": [
                "number"
              ],
              "default": 1,
              "instillUIOrder": 4
            },
            "stream": {
              "title": "Stream",
              "type": "boolean",
              "description": "If set to true, the model will send tokens as they are generated in a streaming manner, rather than waiting for the entire response to be ready.",
              "instillShortDescription": "If set to true, the model will send tokens as they are generated in a streaming manner.",
              "instillAcceptFormats": [
                "boolean"
              ],
              "default": false,
              "instillUIOrder": 5
            }
          },
          "required": [],
          "instillUIOrder": 1,
          "title": "Input Parameter"
        }
      },
      "required": [
        "data"
      ]
    },
    "output": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Chat output",
      "description": "This defines the structure of the output returned by the model after processing the input. It includes the generated chat messages, metadata such as token usage, and other information about the response.",
      "instillShortDescription": "This defines the structure of the output returned by the model after processing the input.",
      "type": "object",
      "properties": {
        "data": {
          "description": "This section defines the structure of the output data returned by the chat task. The output includes chat completion choices generated by the model along with metadata such as the reason for finishing, message content, and creation timestamp. Each generated response is structured as a choice that includes details about the model’s reasoning for ending the response generation, the message content, and the role of the message's author.",
          "instillShortDescription": "This section defines the structure of the output data returned by the chat task.",
          "type": "object",
          "properties": {
            "choices": {
              "title": "Choices",
              "type": "array",
              "description": "This is a list of all the possible chat completion choices generated by the model for a given input. Each choice represents a potential response the model can provide based on the input message.",
              "instillShortDescription": "A list of all the possible chat completion choices generated by the model for a given input.",
              "instillFormat": "array",
              "items": {
                "type": "object",
                "properties": {
                  "finish-reason": {
                    "title": "Finish Reason",
                    "type": "string",
                    "description": "The reason why the model stopped generating tokens for this particular response. It could indicate that the model finished the response naturally, or there could be another stopping criterion.",
                    "instillShortDescription": "The reason why the model stopped generating tokens for this particular response.",
                    "instillFormat": "string",
                    "instillUIOrder": 0
                  },
                  "index": {
                    "title": "Index",
                    "type": "integer",
                    "description": "The index or position of this choice in the list of possible responses. This helps to identify which option is being referred to in a set of choices.",
                    "instillShortDescription": "The index or position of this choice in the list of possible responses.",
                    "instillFormat": "integer",
                    "instillUIOrder": 1
                  },
                  "message": {
                    "title": "Message",
                    "type": "object",
                    "description": "The chat message generated by the model as a response to the input. This includes the text content and the role of the message sender (e.g., user, system, assistant).",
                    "instillShortDescription": "The chat message generated by the model as a response to the input.",
                    "properties": {
                      "content": {
                        "title": "Content",
                        "type": "string",
                        "description": "The actual text content of the generated message. This is what the model suggests as the response based on the given input.",
                        "instillShortDescription": "The actual text content of the generated message.",
                        "instillFormat": "string",
                        "instillUIOrder": 0
                      },
                      "role": {
                        "title": "Role",
                        "type": "string",
                        "description": "The role of the entity that generated the message, such as 'system, 'user', or 'assistant'. This allows differentiation between who is sending the message.",
                        "instillShortDescription": "The role of the entity that generated the message.",
                        "instillFormat": "string",
                        "instillUIOrder": 1
                      }
                    },
                    "required": [],
                    "instillUIOrder": 2
                  },
                  "created": {
                    "title": "Created",
                    "type": "integer",
                    "description": "The Unix timestamp (in seconds) indicating when the chat completion was generated. This timestamp can be used to track when the response was created.",
                    "instillShortDescription": "The Unix timestamp indicating when the chat completion was generated.",
                    "instillFormat": "integer",
                    "instillUIOrder": 3
                  }
                },
                "required": [
                  "finish-reason",
                  "index",
                  "message",
                  "created"
                ]
              },
              "instillUIOrder": 0
            }
          },
          "required": [
            "choices"
          ],
          "instillUIOrder": 0,
          "title": "Output Data"
        },
        "metadata": {
          "description": "This section provides metadata about the task completion, including statistics on the usage of tokens. The metadata helps track how many tokens were used in generating the response and how many tokens were included in the input prompt.",
          "instillShortDescription": "This section provides metadata about the task completion, including statistics on the usage of tokens.",
          "type": "object",
          "properties": {
            "usage": {
              "description": "Provides information about the number of tokens involved in the request and the completion process. It includes prompt tokens, completion tokens, and the total number of tokens used.",
              "instillShortDescription": "Information about the number of tokens involved in the request and the completion process.",
              "type": "object",
              "properties": {
                "completion-tokens": {
                  "title": "Completion Tokens",
                  "type": "integer",
                  "description": "The number of tokens generated in the response. This indicates how many tokens were used in the model's reply.",
                  "instillShortDescription": "The number of tokens generated in the response.",
                  "instillFormat": "integer",
                  "instillUIOrder": 0
                },
                "prompt-tokens": {
                  "title": "Prompt Tokens",
                  "type": "integer",
                  "description": "The number of tokens that were in the input prompt. This counts how many tokens were consumed in processing the initial user query or input.",
                  "instillShortDescription": "The number of tokens in the input prompt.",
                  "instillFormat": "integer",
                  "instillUIOrder": 1
                },
                "total-tokens": {
                  "title": "Total Tokens",
                  "type": "integer",
                  "description": "The total number of tokens used in the entire request, which is the sum of prompt tokens and completion tokens.",
                  "instillShortDescription": "The total number of tokens used in the entire request, which is the sum of prompt tokens and completion tokens.",
                  "instillFormat": "integer",
                  "instillUIOrder": 2
                }
              },
              "required": [
                "completion-tokens",
                "prompt-tokens",
                "total-tokens"
              ],
              "instillUIOrder": 0,
              "title": "Usage"
            }
          },
          "required": [],
          "title": "Output Metadata",
          "instillUIOrder": 1
        }
      },
      "required": [
        "data"
      ]
    }
  },
  "TASK_COMPLETION": {
    "title": "Completion",
    "instillShortDescription": "This task generates natural language responses based on a given input prompt. It uses a specified model to predict and create the most appropriate text, such as completing a sentence or generating an entire passage. Users can control the output by setting parameters like maximum tokens (length of the generated text), temperature (creativity level), top-p (nucleus sampling), and number of choices (how many responses to generate). The task supports dynamic input, including system messages that influence the tone or style of the completion, making it versatile for a wide range of applications, from casual text generation to structured outputs like technical documentation or creative writing.",
    "input": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Completion Input",
      "description": "Input schema for the completion task, providing necessary information such as the model and the prompt.",
      "instillShortDescription": "Input schema of the completion task.",
      "type": "object",
      "properties": {
        "data": {
          "title": "Data",
          "instillUIOrder": 0,
          "description": "Contains the model name and the prompt for generating a response. This section defines the input prompt and guides the model's behavior using the specified system message.",
          "instillShortDescription": "Input data specifying the model and prompt used for completion generation.",
          "type": "object",
          "properties": {
            "model": {
              "description": "Name of the model that generates the text response.",
              "instillShortDescription": "Specifies the model for text generation.",
              "instillAcceptFormats": [
                "string"
              ],
              "instillUIOrder": 0,
              "title": "Model Name",
              "type": "string"
            },
            "system-message": {
              "title": "System Message",
              "type": "string",
              "description": "A message sent by the system to guide the model's behavior, affecting tone, style, or other attributes.",
              "instillShortDescription": "Message guiding the model’s behavior.",
              "instillAcceptFormats": [
                "string"
              ],
              "instillUIOrder": 1
            },
            "prompt": {
              "title": "Input Prompt",
              "type": "string",
              "description": "The input text or query for which the model will generate a response.",
              "instillShortDescription": "Text prompt for model response.",
              "instillAcceptFormats": [
                "string"
              ],
              "instillUIOrder": 2
            }
          },
          "required": [
            "model",
            "prompt"
          ]
        },
        "parameter": {
          "description": "Optional settings to control the model’s behavior, including token limit, randomness, and response length.",
          "instillShortDescription": "Optional parameters for model configuration.",
          "type": "object",
          "title": "Parameter",
          "instillUIOrder": 1,
          "properties": {
            "max-tokens": {
              "title": "Max New okens",
              "type": "integer",
              "description": "Specifies the maximum number of tokens the model is allowed to generate for the response.",
              "instillShortDescription": "Limits the maximum number of tokens generated by the model.",
              "instillAcceptFormats": [
                "integer"
              ],
              "instillUIOrder": 0,
              "default": 50
            },
            "seed": {
              "title": "Seed",
              "type": "integer",
              "description": "A random seed value used to influence the output. Default is 0, ensuring consistent behavior.",
              "instillShortDescription": "The seed used for randomization in generating output.",
              "instillAcceptFormats": [
                "integer"
              ],
              "instillUIOrder": 1,
              "default": 0
            },
            "n": {
              "title": "Number of Choices",
              "type": "integer",
              "description": "Defines how many response choices the model should generate for each input prompt.",
              "instillShortDescription": "Specifies the number of generated choices for each input.",
              "instillAcceptFormats": [
                "integer"
              ],
              "instillUIOrder": 2,
              "default": 1
            },
            "temperature": {
              "title": "Temperature",
              "type": "number",
              "description": "Controls the randomness of the output. Higher values (closer to 1) make responses more diverse.",
              "instillShortDescription": "Adjusts response creativity by setting randomness in token selection.",
              "instillAcceptFormats": [
                "number"
              ],
              "instillUIOrder": 3,
              "default": 0.7
            },
            "top-p": {
              "title": "Top P",
              "type": "number",
              "description": "Nucleus sampling parameter. It considers only tokens within the cumulative top-p probability mass.",
              "instillShortDescription": "Limits token selection to the top-p probability distribution for more focused outputs.",
              "instillAcceptFormats": [
                "number"
              ],
              "instillUIOrder": 4,
              "default": 1
            },
            "stream": {
              "title": "Stream",
              "type": "boolean",
              "description": "When true, sends partial token data as it’s generated, instead of waiting for the entire response.",
              "instillShortDescription": "Enables streaming of token deltas as they are generated.",
              "instillAcceptFormats": [
                "boolean"
              ],
              "instillUIOrder": 5,
              "default": false
            }
          },
          "required": []
        }
      },
      "required": [
        "data"
      ]
    },
    "output": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Chat output",
      "description": "Output schema for the completion task, including generated messages and usage statistics.",
      "instillShortDescription": "Output schema for the completion task",
      "type": "object",
      "properties": {
        "data": {
          "title": "Data",
          "instillUIOrder": 0,
          "description": "Contains the generated responses and details like why the model stopped and when the response was generated.",
          "instillShortDescription": "Contains the generated response choices for the completion task.",
          "type": "object",
          "properties": {
            "choices": {
              "title": "Choices",
              "type": "array",
              "description": "List of generated text responses, each with a reason for completion, index, content, and timestamp.",
              "instillShortDescription": "List of possible completions for the prompt.",
              "instillFormat": "array",
              "instillUIOrder": 0,
              "items": {
                "type": "object",
                "properties": {
                  "finish-reason": {
                    "title": "Finish Reason",
                    "type": "string",
                    "description": "Describes why the model stopped generating tokens, such as reaching the limit or completing naturally.",
                    "instillShortDescription": "Explains why token generation ended (e.g., reached limit, or completed).",
                    "instillFormat": "string",
                    "enum": [
                      "stop",
                      "length"
                    ],
                    "instillUIOrder": 0
                  },
                  "index": {
                    "title": "Index",
                    "type": "integer",
                    "description": "Indicates the position of this choice in the list of generated responses.",
                    "instillShortDescription": "The position of the response in the list of generated choices.",
                    "instillFormat": "integer",
                    "instillUIOrder": 1
                  },
                  "content": {
                    "title": "Content",
                    "type": "string",
                    "description": "The text output generated by the model as the response.",
                    "instillShortDescription": "The generated text content from the model's response.",
                    "instillFormat": "string",
                    "instillUIOrder": 2
                  },
                  "created": {
                    "title": "Created",
                    "type": "integer",
                    "description": "Unix timestamp (in seconds) representing when the response was generated.",
                    "instillShortDescription": "Time when the model generated the response, represented as a Unix timestamp.",
                    "instillFormat": "integer",
                    "instillUIOrder": 3
                  }
                },
                "required": [
                  "finish-reason",
                  "index",
                  "content",
                  "created"
                ]
              }
            }
          },
          "required": [
            "choices"
          ]
        },
        "metadata": {
          "description": "Provides information on how many tokens were used in both the input prompt and the generated response.",
          "instillShortDescription": "Reports token usage for both the input and the response.",
          "title": "Metadata",
          "instillUIOrder": 1,
          "type": "object",
          "properties": {
            "usage": {
              "description": "Provides information on how many tokens were used in both the input prompt and the generated response.",
              "instillShortDescription": "Reports token usage for both the input and the response.",
              "title": "Usage",
              "instillUIOrder": 0,
              "type": "object",
              "properties": {
                "completion-tokens": {
                  "title": "Completion Tokens",
                  "type": "integer",
                  "description": "The number of tokens used in generating the model's completion.",
                  "instillShortDescription": "Tokens used in generating the response.",
                  "instillFormat": "integer",
                  "instillUIOrder": 0
                },
                "prompt-tokens": {
                  "title": "Prompt Tokens",
                  "type": "integer",
                  "description": "The number of tokens in the original input prompt provided to the model.",
                  "instillShortDescription": "Tokens used in the input prompt for generation.",
                  "instillFormat": "integer",
                  "instillUIOrder": 1
                },
                "total-tokens": {
                  "title": "Total tokens",
                  "type": "integer",
                  "description": "The total number of tokens used, combining the prompt and the response.",
                  "instillShortDescription": "Sum of tokens used in both the input and response.",
                  "instillFormat": "integer",
                  "instillUIOrder": 2
                }
              },
              "required": [
                "completion-tokens",
                "prompt-tokens",
                "total-tokens"
              ]
            }
          },
          "required": []
        }
      },
      "required": [
        "data"
      ]
    }
  },
  "TASK_TEXT_TO_IMAGE": {
    "title": "Text To Image",
    "instillShortDescription": "This task allows users to generate detailed images based on textual descriptions. By providing a well-constructed prompt, users can influence various aspects of the generated image, such as composition, colors, and subjects. The model processes the input text to create an image that matches the description as closely as possible. Additional settings, such as controlling the aspect ratio, limiting unwanted elements via negative prompts, and specifying a seed for repeatability, provide flexibility in generating diverse results. This feature is ideal for visual content creation, creative brainstorming, and conceptual design, offering users the ability to convert ideas into visual representations quickly and efficiently. Whether for art, marketing, or prototyping, this task is a powerful tool for transforming words into visuals.",
    "input": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Text to Image Input",
      "description": "The input schema defines the structure for providing data to this task. It includes the model and prompt to generate the image and optional parameters like aspect ratio, negative prompts, and more.",
      "instillShortDescription": "The input schema defines the required model, prompt, and optional settings for generating an image.",
      "type": "object",
      "properties": {
        "data": {
          "title": "Input Data",
          "instillUIOrder": 0,
          "description": "This object contains the necessary data for generating the image. It includes the selected model and the prompt describing the desired elements of the output image.",
          "instillShortDescription": "The required data for generating an image, including the model and a detailed prompt.",
          "type": "object",
          "properties": {
            "model": {
              "description": "The model to be used for generating the image. Specify a model that fits your requirements for image generation.",
              "instillShortDescription": "The model used for image generation.",
              "instillAcceptFormats": [
                "string"
              ],
              "instillUIOrder": 0,
              "title": "Model Name",
              "type": "string"
            },
            "prompt": {
              "title": "Input Prompt",
              "type": "string",
              "description": "The textual description that will guide the image generation. A strong and detailed prompt leads to better results, clearly specifying subjects, colors, and other visual aspects.",
              "instillShortDescription": "Descriptive text prompt for image generation.",
              "instillAcceptFormats": [
                "string"
              ],
              "instillUIOrder": 1
            }
          },
          "required": [
            "model",
            "prompt"
          ]
        },
        "parameter": {
          "title": "Parameter",
          "description": "This section defines optional parameters that modify the behavior of the image generation, such as aspect ratio, negative prompts, and the number of generated choices.",
          "instillShortDescription": "Optional parameters that adjust the image generation process.",
          "instillUIOrder": 1,
          "type": "object",
          "properties": {
            "aspect-ratio": {
              "title": "Aspect Ratio",
              "type": "string",
              "description": "Sets the aspect ratio for the generated image. Defaults to 1:1, but you can choose from other options like 16:9, 4:5, etc.",
              "instillShortDescription": "Defines the image aspect ratio, defaulting to 1:1.",
              "instillAcceptFormats": [
                "string"
              ],
              "default": "1:1",
              "enum": [
                "16:9",
                "1:1",
                "21:9",
                "2:3",
                "3:2",
                "4:5",
                "5:4",
                "9:16",
                "9:21"
              ],
              "instillUIOrder": 0
            },
            "negative-prompt": {
              "title": "Negative Prompt",
              "type": "string",
              "description": "Keywords representing elements you do not want in the generated image, helping to refine the output.",
              "instillShortDescription": "Keywords specifying what to exclude from the image.",
              "instillAcceptFormats": [
                "string"
              ],
              "instillUIOrder": 1,
              "default": ""
            },
            "n": {
              "title": "Number of Choices",
              "type": "integer",
              "description": "The number of image samples to generate for each input prompt. Set the number based on the desired variety of outputs.",
              "instillShortDescription": "Specifies how many image samples to generate for each prompt.",
              "instillAcceptFormats": [
                "integer"
              ],
              "instillUIOrder": 2,
              "default": 1
            },
            "seed": {
              "title": "Seed",
              "type": "integer",
              "description": "A seed value controls the randomness of the output. Using the same seed will produce consistent results. The default value is 0.",
              "instillShortDescription": "Controls the randomization of results. Default seed is 0.",
              "instillAcceptFormats": [
                "integer"
              ],
              "instillUIOrder": 3,
              "default": 0
            }
          },
          "required": []
        }
      },
      "required": [
        "data"
      ]
    },
    "output": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Chat Output",
      "description": "The output schema defines the structure of the result, including the generated images and metadata such as usage statistics and reasons for stopping.",
      "instillShortDescription": "Defines the output format, including generated images and metadata.",
      "type": "object",
      "properties": {
        "data": {
          "title": "Data",
          "instillUIOrder": 0,
          "description": "The data section contains the core output of the image generation task. It includes all relevant information generated by the model, such as the list of created images and their associated metadata, providing a comprehensive result for each input prompt.",
          "instillShortDescription": "Core output containing generated images and related metadata.",
          "type": "object",
          "properties": {
            "choices": {
              "title": "Choices",
              "type": "array",
              "description": "A list containing the generated image samples. Each object in the array includes the image (Base64 encoded) and the reason the generation stopped.",
              "instillShortDescription": "List of generated images and reasons for stopping.",
              "instillFormat": "array",
              "items": {
                "type": "object",
                "properties": {
                  "finish-reason": {
                    "title": "Finish Reason",
                    "type": "string",
                    "description": "Indicates why the model stopped generating tokens, such as reaching success or filtering out inappropriate content.",
                    "instillShortDescription": "Reason why the generation process stopped.",
                    "instillFormat": "string",
                    "enum": [
                      "content_filtered",
                      "success"
                    ],
                    "instillUIOrder": 0
                  },
                  "image": {
                    "title": "Image",
                    "type": "string",
                    "description": "The generated image in Base64 format, ready for use or further processing.",
                    "instillShortDescription": "The generated image encoded in Base64.",
                    "instillFormat": "image/*",
                    "instillUIOrder": 1
                  }
                },
                "required": [
                  "finish-reason",
                  "image"
                ]
              },
              "instillUIOrder": 0
            }
          },
          "required": [
            "choices"
          ]
        },
        "metadata": {
          "title": "Metadata",
          "instillUIOrder": 1,
          "description": "Provides additional details about the image generation request, such as usage statistics and resource consumption.",
          "instillShortDescription": "Additional information about the request, including usage data.",
          "type": "object",
          "properties": {
            "usage": {
              "title": "Usage",
              "instillUIOrder": 0,
              "description": "Tracks how resources were utilized during the request, offering insights into the performance and efficiency of the task.",
              "instillShortDescription": "Details about resource usage during the image generation process.",
              "type": "object",
              "properties": {},
              "required": []
            }
          },
          "required": []
        }
      },
      "required": [
        "data"
      ]
    }
  },
  "TASK_CLASSIFICATION": {
    "title": "Classification",
    "instillShortDescription": "This task focuses on analyzing and categorizing images into predefined groups based on their content. Utilizing advanced machine learning models, this task processes input images and assigns them to specific classes, helping users quickly identify and sort visual data. This capability is particularly valuable in various applications, such as organizing image databases, automating content moderation, or improving search functionalities within image repositories. By leveraging robust algorithms, the Classification task enhances efficiency and accuracy in identifying visual elements, patterns, and anomalies. Users can expect reliable results that streamline workflows and support decision-making processes. With a straightforward input format, this task allows for easy integration into existing systems, empowering users to harness the power of image classification in their projects. Whether for academic research, business intelligence, or creative endeavors, the Classification task serves as a vital tool for transforming images into actionable insights.",
    "input": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Classification Input",
      "instillUIOrder": 0,
      "description": "Defines the structure for submitting data to the classification task. It requires a data object containing the image or visual input to be classified. Optional parameters can be included to customize the classification process. This schema ensures that all necessary information is provided for accurate image categorization, facilitating efficient processing and reliable results.",
      "instillShortDescription": "Schema for submitting images and parameters for classification tasks.",
      "type": "object",
      "properties": {
        "data": {
          "title": "Input Data",
          "instillUIOrder": 0,
          "description": "Contains the input image or visual data for classification. It specifies the image format, either via a URL or as a base64 encoded string. This section ensures that the classification model receives the appropriate input, enhancing the accuracy and efficiency of the classification task.",
          "instillShortDescription": "Input image or visual data for classification tasks via URL or base64.",
          "oneOf": [
            {
              "type": "object",
              "description": "Specifies the classification model to be utilized for the task. This field must contain a valid model name to ensure accurate classification outcomes.",
              "title": "Image URL",
              "properties": {
                "model": {
                  "description": "Specifies the classification model to be utilized for the task. This field must contain a valid model name to ensure accurate classification outcomes.",
                  "instillShortDescription": "Name of the model used for classification.",
                  "instillAcceptFormats": [
                    "string"
                  ],
                  "title": "Model Name",
                  "instillUIOrder": 0,
                  "type": "string"
                },
                "image-url": {
                  "title": "Input Image URL",
                  "description": "Contains the URL of the input image to be classified. This URL must point to a valid image resource for processing.",
                  "instillShortDescription": "URL of the image for classification.",
                  "instillAcceptFormats": [
                    "string"
                  ],
                  "instillUIOrder": 2,
                  "type": "string"
                },
                "type": {
                  "title": "URL",
                  "description": "Indicates the type of input being submitted, set to `image-url` for this option. This field is essential for the classification model to understand the format of the input data.",
                  "instillShortDescription": "Type identifier for URL input.",
                  "instillAcceptFormats": [
                    "string"
                  ],
                  "type": "string",
                  "instillUIOrder": 1,
                  "const": "image-url"
                }
              },
              "required": [
                "model",
                "image-url",
                "type"
              ]
            },
            {
              "type": "object",
              "description": "Specifies the classification model to be utilized for the task. This field must contain a valid model name to ensure accurate classification outcomes.",
              "title": "Image Base64",
              "properties": {
                "model": {
                  "description": "Specifies the classification model to be utilized for the task. This field must contain a valid model name to ensure accurate classification outcomes.",
                  "instillShortDescription": "Name of the model used for classification.",
                  "instillAcceptFormats": [
                    "string"
                  ],
                  "title": "Model Name",
                  "instillUIOrder": 0,
                  "type": "string"
                },
                "image-base64": {
                  "title": "Input Image File",
                  "description": "Contains the base64-encoded string of the input image file to be classified. This format allows for direct submission of image data without requiring an external URL.",
                  "instillShortDescription": "Base64-encoded image file for classification.",
                  "instillAcceptFormats": [
                    "image/*"
                  ],
                  "instillUIOrder": 2,
                  "type": "string"
                },
                "type": {
                  "title": "File",
                  "description": "Indicates the type of input being submitted, set to `image-base64` for this option. This field helps the classification model to identify the format of the input data.",
                  "instillShortDescription": "Type identifier for base64 input.",
                  "instillAcceptFormats": [
                    "string"
                  ],
                  "instillUIOrder": 1,
                  "type": "string",
                  "const": "image-base64"
                }
              },
              "required": [
                "model",
                "image-base64",
                "type"
              ]
            }
          ],
          "type": "object",
          "required": [
            "model"
          ]
        },
        "parameter": {
          "title": "Parameter",
          "instillUIOrder": 1,
          "description": "The parameter property allows for the inclusion of optional settings or configurations that may influence the classification process. While no specific properties are defined, this field enables users to customize the classification task as needed.",
          "instillShortDescription": "Optional parameters for customizing the classification task.",
          "type": "object",
          "properties": {},
          "required": []
        }
      },
      "required": [
        "data"
      ]
    },
    "output": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "title": "Classification Output",
      "description": "Describes the structure of the results returned after processing the classification task. It includes a data object that contains the classification results, such as the assigned categories or labels for the input images. Additionally, it provides metadata containing usage statistics related to the request, offering insights into the processing of the classification task. This schema ensures users receive clear and structured outputs for effective decision-making.",
      "instillShortDescription": "Structure of classification results and associated usage statistics.",
      "instillUIOrder": 1,
      "type": "object",
      "properties": {
        "data": {
          "title": "Data",
          "instillUIOrder": 0,
          "description": "Contains the results of the classification task, including the predicted category and its associated confidence score. This structured output allows users to understand the model's classification decision and assess its reliability based on the score provided.",
          "instillShortDescription": "Results of the classification, including predicted category and score.",
          "type": "object",
          "properties": {
            "category": {
              "description": "Represents the predicted category assigned to the input image. This field provides the model's classification result, helping users identify how the input is categorized.",
              "instillShortDescription": "Predicted category for the input image.",
              "instillFormat": "string",
              "title": "Category",
              "instillUIOrder": 0,
              "type": "string"
            },
            "score": {
              "description": "Indicates the confidence score associated with the predicted category, reflecting how certain the model is about its classification. A higher score signifies greater confidence in the assigned category.",
              "instillShortDescription": "Confidence score of the predicted category.",
              "instillFormat": "number",
              "title": "Score",
              "instillUIOrder": 1,
              "type": "number"
            }
          },
          "required": [
            "category",
            "score"
          ]
        },
        "metadata": {
          "title": "Metadata",
          "instillUIOrder": 1,
          "description": "Contains additional information about the request, including usage statistics. This data provides context and insights regarding the classification process, helping users evaluate performance and resource consumption during the classification task.",
          "instillShortDescription": "Additional information and usage statistics for the classification request.",
          "type": "object",
          "properties": {
            "usage": {
              "title": "Usage",
              "instillUIOrder": 0,
              "description": "Contains statistics related to the usage of the classification request. This field can provide insights into how resources were utilized during processing, although no specific properties are defined within it.",
              "instillShortDescription": "Statistics on resource usage for the classification request.",
              "type": "object",
              "properties": {},
              "required": []
            }
          },
          "required": []
        }
      },
      "required": [
        "data"
      ]
    }
  }
}
