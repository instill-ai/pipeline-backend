---
title: "Fireworks AI"
lang: "en-US"
draft: false
description: "Learn about how to set up a VDP Fireworks AI component https://github.com/instill-ai/instill-core"
---

The Fireworks AI component is an AI component that allows users to connect the AI models served on the Fireworks AI Platform.
It can carry out the following tasks:
- [Text Generation Chat](#text-generation-chat)
- [Text Embeddings](#text-embeddings)



## Release Stage

`Alpha`



## Configuration

The component definition and tasks are defined in the [definition.yaml](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/ai/fireworksai/v0/config/definition.yaml) and [tasks.yaml](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/ai/fireworksai/v0/config/tasks.yaml) files respectively.




## Setup


In order to communicate with Fireworks AI, the following connection details need to be
provided. You may specify them directly in a pipeline recipe as key-value pairs
within the component's `setup` block, or you can create a **Connection** from
the [**Integration Settings**](https://www.instill.tech/docs/vdp/integration)
page and reference the whole `setup` as `setup:
${connection.<my-connection-id>}`.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| API Key | `api-key` | string | Fill in your Fireworks AI API key. To find your keys, visit the Fireworks AI API Keys page.  |

</div>





## Supported Tasks

### Text Generation Chat

Fireworks AI's text generation models (often called generative pre-trained transformers or large language models) have been trained to understand natural language, code, and images. The models provide text outputs in response to their inputs. The inputs to these models are also referred to as "prompts". Designing a prompt is essentially how you “program” a large language model model, usually by providing instructions or some examples of how to successfully complete a task.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_TEXT_GENERATION_CHAT` |
| Model Name (required) | `model` | string | The OSS model to be used. <br/><details><summary><strong>Enum values</strong></summary><ul><li>`llama-v3p1-405b-instruct`</li><li>`llama-v3p1-70b-instruct`</li><li>`llama-v3p1-8b-instruct`</li><li>`llama-v3-70b-instruct`</li><li>`llama-v3-8b-instruct`</li><li>`firellava-13b`</li><li>`firefunction-v2`</li><li>`deepseek-coder-v2-instruct`</li><li>`deepseek-coder-v2-lite-instruct`</li><li>`starcoder-16b`</li><li>`starcoder-7b`</li><li>`phi-3-vision-128k-instruct`</li><li>`qwen2-72b-instruct`</li><li>`mythomax-l2-13b`</li><li>`yi-large`</li></ul></details>  |
| Prompt (required) | `prompt` | string | The prompt text. |
| System Message | `system-message` | string | The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model’s behavior is set using a generic message as "You are a helpful assistant.". |
| Prompt Images | `prompt-images` | array[string] | The prompt images (Note: According to Fireworks AI documentation on 2024-07-24, the total number of images included in a single API request should not exceed 30, and all the images should be smaller than 5MB in size). |
| [Chat History](#text-generation-chat-chat-history) | `chat-history` | array[object] | Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: : \{"role": "The message role, i.e. 'system', 'user' or 'assistant'", "content": "message content"\}. |
| Seed | `seed` | integer | The seed. |
| Temperature | `temperature` | number | The temperature for sampling. |
| Top K | `top-k` | integer | Integer to define the top tokens considered within the sample operation to create new text. |
| Max New Tokens | `max-new-tokens` | integer | The maximum number of tokens for model to generate. |
| Top P | `top-p` | number | Float to define the tokens that are within the sample operation of text generation. Add tokens in the sample for more probable to least probable until the sum of the probabilities is greater than top-p (default=0.5). |
</div>


<details>
<summary> Input Objects in Text Generation Chat</summary>

<h4 id="text-generation-chat-chat-history">Chat History</h4>

Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: : \{"role": "The message role, i.e. 'system', 'user' or 'assistant'", "content": "message content"\}.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| [Content](#text-generation-chat-content) | `content` | array | The message content.  |
| Role | `role` | string | The message role, i.e. 'system', 'user' or 'assistant'.  |
</div>
<h4 id="text-generation-chat-content">Content</h4>

The message content.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| [Image URL](#text-generation-chat-image-url) | `image-url` | object | The image URL.  |
| Text | `text` | string | The text content.  |
| Type | `type` | string | The type of the content part.  <br/><details><summary><strong>Enum values</strong></summary><ul><li>`text`</li><li>`image_url`</li></ul></details>  |
</div>
<h4 id="text-generation-chat-image-url">Image URL</h4>

The image URL.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| URL | `url` | string | Either a URL of the image or the base64 encoded image data.  |
</div>
</details>



<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Text | `text` | string | Model Output. |
| [Usage](#text-generation-chat-usage) (optional) | `usage` | object | Token usage on the Fireworks AI platform text generation models. |
</div>

<details>
<summary> Output Objects in Text Generation Chat</summary>

<h4 id="text-generation-chat-usage">Usage</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Input Tokens | `input-tokens` | number | The input tokens used by Fireworks AI models. |
| Output Tokens | `output-tokens` | number | The output tokens generated by Fireworks AI models. |
</div>
</details>


### Text Embeddings

An embedding is a list of floating point numbers that captures semantic information about the text that it represents.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Input | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_TEXT_EMBEDDINGS` |
| Model Name (required) | `model` | string | The OSS embedding model to be used. <br/><details><summary><strong>Enum values</strong></summary><ul><li>`nomic-ai/nomic-embed-text-v1.5`</li><li>`nomic-ai/nomic-embed-text-v1`</li><li>`WhereIsAI/UAE-Large-V1`</li><li>`thenlper/gte-large`</li><li>`thenlper/gte-base`</li></ul></details>  |
| Text (required) | `text` | string | The text. |
</div>






<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Output | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Embedding | `embedding` | array[number] | Embedding of the input text. |
| [Usage](#text-embeddings-usage) (optional) | `usage` | object | Token usage on the Fireworks AI platform embedding models. |
</div>

<details>
<summary> Output Objects in Text Embeddings</summary>

<h4 id="text-embeddings-usage">Usage</h4>

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Token Count | `tokens` | number | The token count used by Fireworks AI models. |
</div>
</details>



## Example Recipes

Recipe for the [Fireworks Chinese Content Writer](https://instill.tech/instill-ai/pipelines/fireworks-chinese-content-writer/playground) pipeline.

```yaml
version: v1beta
component:
  fireworks-0:
    type: fireworks-ai
    task: TASK_TEXT_GENERATION_CHAT
    input:
      max-new-tokens: 200
      model: qwen2-72b-instruct
      prompt: ${variable.prompt}
      system-message: You are a expert social media content writing assistant. Output the result in chinese for 小紅書.
      temperature: 0.05
      top-k: 10
      top-p: 0.5
    setup:
      api-key: ${secret.INSTILL_SECRET}
variable:
  prompt:
    title: prompt
    description: input prompt i.e. "寫一份生椰拿鐵文案", "write about horses"
    type: string
output:
  output:
    title: output
    value: ${fireworks-0.output.text}
```
