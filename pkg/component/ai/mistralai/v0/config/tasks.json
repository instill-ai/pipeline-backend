{
  "$defs": {
    "multi-modal-content": {
      "instillFormat": "structured/multi-modal-content",
      "items": {
        "properties": {
          "image-url": {
            "properties": {
              "url": {
                "description": "Either a URL of the image or the base64 encoded image data.",
                "type": "string",
                "title": "URL",
                "instillUIOrder": 0
              }
            },
            "required": [
              "url"
            ],
            "title": "Image URL",
            "description": "The image URL",
            "instillUIOrder": 0,
            "type": "object"
          },
          "text": {
            "description": "The text content.",
            "instillFormat": "string",
            "title": "Text",
            "instillUIOrder": 1,
            "type": "string"
          },
          "type": {
            "description": "The type of the content part.",
            "enum": [
              "text",
              "image_url"
            ],
            "instillFormat": "string",
            "title": "Type",
            "instillUIOrder": 2,
            "type": "string"
          }
        },
        "required": [
          "type"
        ],
        "type": "object"
      },
      "type": "array"
    },
    "chat-message": {
      "properties": {
        "content": {
          "$ref": "#/$defs/multi-modal-content",
          "description": "The message content",
          "instillUIOrder": 1,
          "title": "Content"
        },
        "role": {
          "description": "The message role, i.e. 'system', 'user' or 'assistant'",
          "instillFormat": "string",
          "instillUIOrder": 0,
          "title": "Role",
          "type": "string"
        }
      },
      "required": [
        "role",
        "content"
      ],
      "title": "Chat Message",
      "type": "object"
    },
    "chat-usage": {
      "description": "Token usage on the Mistral platform text generation models",
      "instillUIOrder": 1,
      "properties": {
        "input-tokens": {
          "description": "The input tokens used by Mistral models",
          "instillFormat": "number",
          "instillUIOrder": 2,
          "title": "Input Tokens",
          "type": "number"
        },
        "output-tokens": {
          "description": "The output tokens generated by Mistral models",
          "instillFormat": "number",
          "instillUIOrder": 3,
          "title": "Output Tokens",
          "type": "number"
        }
      },
      "required": [
        "input-tokens",
        "output-tokens"
      ],
      "title": "Usage",
      "type": "object"
    },
    "embedding-usage": {
      "description": "Token usage on the Mistral platform embedding models",
      "instillUIOrder": 1,
      "properties": {
        "tokens": {
          "description": "The token count used by Mistral models",
          "instillFormat": "number",
          "instillUIOrder": 1,
          "title": "Token Count",
          "type": "number"
        }
      },
      "required": [
        "tokens"
      ],
      "title": "Usage",
      "type": "object"
    }
  },
  "TASK_TEXT_GENERATION_CHAT": {
    "instillShortDescription": "Provide text outputs in response to text inputs.",
    "description": "Mistral AI's text generation models (often called generative pre-trained transformers or large language models) have been trained to understand natural language, code, and images. The models provide text outputs in response to their inputs. The inputs to these models are also referred to as \"prompts\". Designing a prompt is essentially how you \u201cprogram\u201d a large language model model, usually by providing instructions or some examples of how to successfully complete a task",
    "input": {
      "description": "Input",
      "instillEditOnNodeFields": [
        "prompt",
        "model-name"
      ],
      "instillUIOrder": 0,
      "properties": {
        "chat-history": {
          "description": "Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: : {\"role\": \"The message role, i.e. 'system', 'user' or 'assistant'\", \"content\": \"message content\"}",
          "instillAcceptFormats": [
            "structured/chat-messages"
          ],
          "instillShortDescription": "Incorporate external chat history, specifically previous messages within the conversation. (Note: The Mistral models are not trained to process images, thus images will be omitted)",
          "instillUIOrder": 4,
          "instillUpstreamTypes": [
            "reference"
          ],
          "items": {
            "$ref": "#/$defs/chat-message"
          },
          "title": "Chat history",
          "type": "array"
        },
        "max-new-tokens": {
          "default": 50,
          "description": "The maximum number of tokens for model to generate",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 6,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Max New Tokens",
          "type": "integer"
        },
        "model-name": {
          "enum": [
            "open-mixtral-8x22b",
            "open-mixtral-8x7b",
            "open-mistral-7b",
            "mistral-large-latest",
            "mistral-small-latest",
            "codestral-latest"
          ],
          "example": "open-mixtral-8x22b",
          "description": "The Mistral model to be used",
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIOrder": 0,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "instillCredentialMap": {
            "values": [
              "open-mixtral-8x22b",
              "open-mixtral-8x7b",
              "open-mistral-7b",
              "mistral-large-latest",
              "mistral-small-latest",
              "codestral-latest"
            ],
            "targets": [
              "setup.api-key"
            ]
          },
          "title": "Model Name",
          "type": "string"
        },
        "prompt": {
          "description": "The prompt text",
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIMultiline": true,
          "instillUIOrder": 2,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "prompt-images": {
          "description": "The prompt images (Note: The Mistral models are not trained to process images, thus images will be omitted)",
          "instillAcceptFormats": [
            "array:image/*"
          ],
          "instillUIOrder": 3,
          "instillUpstreamTypes": [
            "reference"
          ],
          "items": {
            "type": "string"
          },
          "title": "Prompt Images",
          "type": "array"
        },
        "seed": {
          "description": "The seed",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 4,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Seed",
          "type": "integer"
        },
        "system-message": {
          "default": "You are a helpful assistant.",
          "description": "The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model\u2019s behavior is set using a generic message as \"You are a helpful assistant.\"",
          "instillAcceptFormats": [
            "string"
          ],
          "instillShortDescription": "The system message helps set the behavior of the assistant",
          "instillUIMultiline": true,
          "instillUIOrder": 2,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "System Message",
          "type": "string"
        },
        "temperature": {
          "default": 0.7,
          "description": "The temperature for sampling",
          "instillAcceptFormats": [
            "number"
          ],
          "instillUIOrder": 5,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Temperature",
          "type": "number"
        },
        "top-k": {
          "default": 10,
          "description": "Integer to define the top tokens considered within the sample operation to create new text (Note: The Mistral models does not support top-k sampling)",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 5,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Top K",
          "type": "integer"
        },
        "top-p": {
          "default": 0.5,
          "description": "Float to define the tokens that are within the sample operation of text generation. Add tokens in the sample for more probable to least probable until the sum of the probabilities is greater than top-p (default=0.5)",
          "instillAcceptFormats": [
            "number",
            "integer"
          ],
          "instillShortDescription": "Float to define the tokens that are within the sample operation of text generation",
          "instillUIOrder": 6,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Top P",
          "type": "number"
        },
        "safe": {
          "description": "Safe generation mode",
          "instillAcceptFormats": [
            "boolean"
          ],
          "instillUIOrder": 7,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Safe",
          "type": "boolean"
        }
      },
      "required": [
        "prompt",
        "model-name"
      ],
      "title": "Input",
      "type": "object"
    },
    "output": {
      "description": "Output",
      "instillUIOrder": 0,
      "properties": {
        "text": {
          "description": "Model Output",
          "instillUIOrder": 0,
          "instillFormat": "string",
          "instillUIMultiline": true,
          "title": "Text",
          "type": "string"
        },
        "usage": {
          "$ref": "#/$defs/chat-usage"
        }
      },
      "required": [
        "text"
      ],
      "title": "Output",
      "type": "object"
    }
  },
  "TASK_TEXT_EMBEDDINGS": {
    "instillShortDescription": "Turn text into a vector of numbers that capture its meaning, unlocking use cases like semantic search.",
    "description": "An embedding is a list of floating point numbers that captures semantic information about the text that it represents.",
    "input": {
      "instillUIOrder": 0,
      "properties": {
        "model-name": {
          "enum": [
            "mistral-embed"
          ],
          "example": "mistral-embed",
          "description": "The Mistral embed model to be used",
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIOrder": 0,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Model Name",
          "type": "string",
          "instillCredentialMap": {
            "values": [
              "mistral-embed"
            ],
            "targets": [
              "setup.api-key"
            ]
          }
        },
        "text": {
          "description": "The text",
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIMultiline": true,
          "instillUIOrder": 1,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Text",
          "type": "string"
        }
      },
      "required": [
        "text",
        "model-name"
      ],
      "instillEditOnNodeFields": [
        "text",
        "model-name"
      ],
      "title": "Input",
      "type": "object"
    },
    "output": {
      "instillUIOrder": 0,
      "properties": {
        "embedding": {
          "instillFormat": "array:number",
          "items": {
            "instillFormat": "number",
            "title": "Embedding",
            "type": "number"
          },
          "type": "array",
          "description": "Embedding of the input text",
          "instillUIOrder": 0,
          "title": "Embedding"
        },
        "usage": {
          "$ref": "#/$defs/embedding-usage"
        }
      },
      "required": [
        "embedding"
      ],
      "title": "Output",
      "type": "object"
    }
  }
}
