---
title: "Anthropic"
lang: "en-US"
draft: false
description: "Learn about how to set up a Anthropic component https://github.com/instill-ai/instill-core"
---

The Anthropic component is an AI component that allows users to connect the AI models served on the Anthropic Platform.
It can carry out the following tasks:
- [Text Generation Chat](#text-generation-chat)



## Release Stage

`Alpha`



## Configuration

The component definition and tasks are defined in the [definition.yaml](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/ai/anthropic/v0/config/definition.yaml) and [tasks.yaml](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/ai/anthropic/v0/config/tasks.yaml) files respectively.




## Setup


In order to communicate with Anthropic, the following connection details need to be
provided. You may specify them directly in a pipeline recipe as key-value pairs
within the component's `setup` block, or you can create a **Connection** from
the [**Integration Settings**](https://docs.instill-ai.com/docs/set-up-component)
page and reference the whole `setup` as `setup:
${connection.<my-connection-id>}`.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| API Key | `api-key` | string | Fill in your Anthropic API key. To find your keys, visit the Anthropic console page. |

</div>





## Supported Tasks

### Text Generation Chat

Anthropic's text generation models (often called generative pre-trained transformers or large language models) have been trained to understand natural language, code, and images. The models provide text outputs in response to their inputs. The inputs to these models are also referred to as "prompts". Designing a prompt is essentially how you “program” a large language model model, usually by providing instructions or some examples of how to successfully complete a task.

<h4 id="text-generation-chat-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_TEXT_GENERATION_CHAT` |
| Model Name (required) | `model-name` | string<br/><small><small><details><summary>Enum values</summary><ul><li>`claude-3-5-sonnet-latest`</li><li>`claude-3-5-sonnet-20241022`</li><li>`claude-3-5-sonnet-20240620`</li><li>`claude-3-opus-20240229`</li><li>`claude-3-sonnet-20240229`</li><li>`claude-3-haiku-20240307`</li></ul></details></small></small> | The Anthropic model to be used. |
| Prompt (required) | `prompt` | string | The prompt text. |
| System Message | `system-message` | string | The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model's behavior is set using a generic message as "You are a helpful assistant.". |
| Prompt Images | `prompt-images` | array[string] | The prompt images (Note: The prompt images will be injected in the order they are provided to the 'prompt' message. Anthropic doesn't support sending images via image-url, use this field instead). |
| Chat History | `chat-history` | array[object ([chat-message](#text-generation-chat-chat-message))] | Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: \{"role": "The message role, i.e. `system`, `user` or `assistant`", "content": "message content"\}. |
| Seed | `seed` | integer | The seed (Note: Not supported by Anthropic Models). |
| Temperature | `temperature` | number | The temperature for sampling. |
| Top K | `top-k` | integer | Top k for sampling. |
| Max New Tokens | `max-new-tokens` | integer | The maximum number of tokens for model to generate. |
</div>

<h4 id="text-generation-chat-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Text | `text` | string | Model Output. |
| Usage (optional) | `usage` | object ([usage](#text-generation-chat-usage)) | Usage tokens in Anthropic. |
</div>

<details>
<summary> Referenced Objects</summary>
<h4 id="text-generation-chat-chat-message">Chat Message <sup><small><small>Referenced in <a href="#text-generation-chat-input">Input</a></small></small></sup></h4>

Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: \{"role": "The message role, i.e. `system`, `user` or `assistant`", "content": "message content"\}.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Role | `role` | string | The message role, i.e. 'system', 'user' or 'assistant'. |
| Content | `content` | array[object ([multi-modal-content](#text-generation-chat-multi-modal-content))] | The message content. |
</div>

<h4 id="text-generation-chat-content">Content <sup><small><small>Referenced in <a href="#text-generation-chat-chat-message">Chat Message</a></small></small></sup></h4>

The message content.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Image URL | `image-url` | object ([chat-message](#text-generation-chat-chat-message)) | The image URL. |
| Text | `text` | string | The text content. |
| Type | `type` | string<br/><small><small><details><summary>Enum values</summary><ul><li>`text`</li><li>`image_url`</li></ul></details></small></small> | The type of the content part. |
</div>

<h4 id="text-generation-chat-image-url">Image URL <sup><small><small>Referenced in <a href="#text-generation-chat-content">Content</a></small></small></sup></h4>

The image URL.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| URL | `url` | string | Either a URL of the image or the base64 encoded image data. |
</div>

<h4 id="text-generation-chat-multi-modal-content">Multi Modal Content</h4>


<h4 id="text-generation-chat-usage">Usage <sup><small><small>Referenced in <a href="#text-generation-chat-output">Output</a></small></small></sup></h4>

Usage tokens in Anthropic.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Input Tokens | `input-tokens` | number | The input tokens used by Anthropic. |
| Output Tokens | `output-tokens` | number | The output tokens used by Anthropic. |
</div>

</details>



## Example Recipes

```yaml
version: v1beta
component:
  anthropic-0:
    type: anthropic
    task: TASK_TEXT_GENERATION_CHAT
    input:
      max-new-tokens: 1000
      model-name: claude-3-5-sonnet-latest
      prompt: Summarise and pick the most important issues from this list ${github.output.issues}
      system-message: You are a helpful assistant.
      temperature: 0.7
      top-k: 10
  github:
    type: github
    task: TASK_LIST_ISSUES
    input:
      direction: desc
      no-pull-request: false
      owner: ${variable.repository-owner}
      page: 1
      per-page: 30
      repository: ${variable.repository-name}
      since: "2021-01-01T00:00:00Z"
      sort: created
      state: open
    setup:
      token: ${secret.github-demo}
variable:
  repository-name:
    title: Repository Name
    description: Name of the repository i.e. instill-core
    type: string
  repository-owner:
    title: Repository Owner
    description: Name of the repository owner i.e. instill-ai
    type: string
output:
  result:
    title: Result
    value: ${anthropic-0.output.text}
```
