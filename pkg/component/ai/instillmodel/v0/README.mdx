---
title: "Instill Model"
lang: "en-US"
draft: false
description: "Learn about how to set up a Instill Model component https://github.com/instill-ai/instill-core"
---

The Instill Model component is an AI component that allows users to connect the Al models served in the Instill Core platform.
It can carry out the following tasks:
- [Classification](#classification)
- [Instance Segmentation](#instance-segmentation)
- [Keypoint](#keypoint)
- [Detection](#detection)
- [OCR](#ocr)
- [Semantic Segmentation](#semantic-segmentation)
- [Text Generation](#text-generation)
- [Text Generation Chat](#text-generation-chat)
- [Text to Image](#text-to-image)
- [Visual Question Answering](#visual-question-answering)
- [Chat](#chat)
- [Embedding](#embedding)



## Release Stage

`Alpha`



## Configuration

The component definition and tasks are defined in the [definition.yaml](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/ai/instill/v0/config/definition.yaml) and [tasks.yaml](https://github.com/instill-ai/pipeline-backend/blob/main/pkg/component/ai/instill/v0/config/tasks.yaml) files respectively.







## Supported Tasks

### Classification

Classify images into predefined categories.

<h4 id="classification-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_CLASSIFICATION` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>

<h4 id="classification-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Category | `category` | string | The predicted category of the input. |
| Score | `score` | number | The confidence score of the predicted category of the input. |
</div>


### Instance Segmentation

Detect, localize and delineate multiple objects in images.

<h4 id="instance-segmentation-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_INSTANCE_SEGMENTATION` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>

<h4 id="instance-segmentation-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Objects | `objects` | array[object ([objects](#instance-segmentation-object))] | A list of detected instance bounding boxes. |
</div>

<details>
<summary> Referenced Objects</summary>
<h4 id="instance-segmentation-bounding-box">Bounding Box <sup><small><small>Referenced in <a href="#instance-segmentation-object">Object</a></small></small></sup></h4>

The detected bounding box in (left, top, width, height) format.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Left | `left` | number | Bounding box left x-axis value |
| Top | `top` | number | Bounding box top y-axis value |
| Width | `width` | number | Bounding box width value |
| Height | `height` | number | Bounding box height value |
</div>

<h4 id="instance-segmentation-object">Object <sup><small><small>Referenced in <a href="#instance-segmentation-output">Output</a></small></small></sup></h4>

A list of detected instance bounding boxes.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| RLE | `rle` | string | Run Length Encoding (RLE) of instance mask within the bounding box. |
| Bounding Box | `bounding-box` | object ([bounding-box](#instance-segmentation-bounding-box)) | The detected bounding box in (left, top, width, height) format. |
| Category | `category` | string | The predicted category of the bounding box. |
| Score | `score` | number | The confidence score of the predicted instance object. |
</div>

</details>


### Keypoint

Detect and localize multiple keypoints of objects in images.

<h4 id="keypoint-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_KEYPOINT` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>

<h4 id="keypoint-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Objects | `objects` | array[object ([objects](#keypoint-object))] | A list of keypoint objects, a keypoint object includes all the pre-defined keypoints of a detected object. |
</div>

<details>
<summary> Referenced Objects</summary>
<h4 id="keypoint-bounding-box">Bounding Box <sup><small><small>Referenced in <a href="#keypoint-object">Object</a></small></small></sup></h4>

The detected bounding box in (left, top, width, height) format.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Left | `left` | number | Bounding box left x-axis value |
| Top | `top` | number | Bounding box top y-axis value |
| Width | `width` | number | Bounding box width value |
| Height | `height` | number | Bounding box height value |
</div>

<h4 id="keypoint-keypoints">Keypoints <sup><small><small>Referenced in <a href="#keypoint-object">Object</a></small></small></sup></h4>

A keypoint group is composed of a list of pre-defined keypoints of a detected object.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| X Coordinate | `x` | number | x coordinate of the keypoint. |
| Y Coordinate | `y` | number | y coordinate of the keypoint. |
| Visibility Score | `v` | number | visibility score of the keypoint. |
</div>

<h4 id="keypoint-object">Object <sup><small><small>Referenced in <a href="#keypoint-output">Output</a></small></small></sup></h4>

A list of keypoint objects, a keypoint object includes all the pre-defined keypoints of a detected object.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Keypoints | `keypoints` | array[object ([keypoints](#keypoint-keypoints))] | A keypoint group is composed of a list of pre-defined keypoints of a detected object. |
| Score | `score` | number | The confidence score of the predicted object. |
| Bounding Box | `bounding-box` | object ([bounding-box](#keypoint-bounding-box)) | The detected bounding box in (left, top, width, height) format. |
</div>

</details>


### Detection

Detect and localize multiple objects in images.

<h4 id="detection-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_DETECTION` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>

<h4 id="detection-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Objects | `objects` | array[object ([objects](#detection-object))] | A list of detected objects. |
</div>

<details>
<summary> Referenced Objects</summary>
<h4 id="detection-bounding-box">Bounding box <sup><small><small>Referenced in <a href="#detection-object">Object</a></small></small></sup></h4>

The detected bounding box in (left, top, width, height) format.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Left | `left` | number | Bounding box left x-axis value |
| Top | `top` | number | Bounding box top y-axis value |
| Width | `width` | number | Bounding box width value |
| Height | `height` | number | Bounding box height value |
</div>

<h4 id="detection-object">Object <sup><small><small>Referenced in <a href="#detection-output">Output</a></small></small></sup></h4>

A list of detected objects.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Bounding box | `bounding-box` | object ([bounding-box](#detection-bounding-box)) | The detected bounding box in (left, top, width, height) format. |
| Category | `category` | string | The predicted category of the bounding box. |
| Score | `score` | number | The confidence score of the predicted category of the bounding box. |
</div>

</details>


### OCR

Detect and recognize text in images.

<h4 id="ocr-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_OCR` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>

<h4 id="ocr-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Objects | `objects` | array[object ([objects](#ocr-object))] | A list of detected bounding boxes. |
</div>

<details>
<summary> Referenced Objects</summary>
<h4 id="ocr-bounding-box">Bounding Box <sup><small><small>Referenced in <a href="#ocr-object">Object</a></small></small></sup></h4>

The detected bounding box in (left, top, width, height) format.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Left | `left` | number | Bounding box left x-axis value |
| Top | `top` | number | Bounding box top y-axis value |
| Width | `width` | number | Bounding box width value |
| Height | `height` | number | Bounding box height value |
</div>

<h4 id="ocr-object">Object <sup><small><small>Referenced in <a href="#ocr-output">Output</a></small></small></sup></h4>

A list of detected bounding boxes.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Bounding Box | `bounding-box` | object ([bounding-box](#ocr-bounding-box)) | The detected bounding box in (left, top, width, height) format. |
| Text | `text` | string | Text string recognised per bounding box. |
| Score | `score` | number | The confidence score of the predicted object. |
</div>

</details>


### Semantic Segmentation

Classify image pixels into predefined categories.

<h4 id="semantic-segmentation-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_SEMANTIC_SEGMENTATION` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Image (required) | `image-base64` | string | Image base64. |
</div>

<h4 id="semantic-segmentation-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Stuffs | `stuffs` | array[object ([common](#semantic-segmentation-common))] | A list of RLE binary masks. |
</div>

<details>
<summary> Referenced Objects</summary>
<h4 id="semantic-segmentation-object">Object <sup><small><small>Referenced in <a href="#semantic-segmentation-output">Output</a></small></small></sup></h4>

A list of RLE binary masks.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| RLE | `rle` | string | Run Length Encoding (RLE) of each stuff mask within the image. |
| Category | `category` | string | Category text string corresponding to each stuff mask. |
</div>

</details>


### Text Generation

Generate texts from input text prompts.

<h4 id="text-generation-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_TEXT_GENERATION` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Prompt (required) | `prompt` | string | The prompt text. |
| System Message | `system-message` | string | The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model's behavior is using a generic message as "You are a helpful assistant.". |
| Seed | `seed` | integer | The seed. |
| Temperature | `temperature` | number | The temperature for sampling. |
| Max New Tokens | `max-new-tokens` | integer | The maximum number of tokens for model to generate. |
</div>

<h4 id="text-generation-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Text | `text` | string | Text. |
</div>


### Text Generation Chat

Generate texts from input text prompts and chat history.

<h4 id="text-generation-chat-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_TEXT_GENERATION_CHAT` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Prompt (required) | `prompt` | string | The prompt text. |
| System Message | `system-message` | string | The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model's behavior is using a generic message as "You are a helpful assistant.". |
| Prompt Images | `prompt-images` | array[string] | The prompt images. |
| Chat History | `chat-history` | array[object ([chat-message](#text-generation-chat-chat-message))] | Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: \{"role": "The message role, i.e. `system`, `user` or `assistant`", "content": "message content"\}. |
| Seed | `seed` | integer | The seed. |
| Temperature | `temperature` | number | The temperature for sampling. |
| Max New Tokens | `max-new-tokens` | integer | The maximum number of tokens for model to generate. |
</div>

<h4 id="text-generation-chat-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Text | `text` | string | Text. |
</div>

<details>
<summary> Referenced Objects</summary>
<h4 id="text-generation-chat-chat-message">Chat Message <sup><small><small>Referenced in <a href="#text-generation-chat-input">Input</a></small></small></sup></h4>

Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: \{"role": "The message role, i.e. `system`, `user` or `assistant`", "content": "message content"\}.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Role | `role` | string | The message role, i.e. 'system', 'user' or 'assistant'. |
| Content | `content` | array[object ([content](#text-generation-chat-content))] | The message content. |
</div>

<h4 id="text-generation-chat-content">Content <sup><small><small>Referenced in <a href="#text-generation-chat-chat-message">Chat Message</a></small></small></sup></h4>

The message content.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Image URL | `image-url` | object ([chat-message](#text-generation-chat-chat-message)) | The image URL |
| Text | `text` | string | The text content. |
| Type | `type` | string<br/><small><small><details><summary>Enum values</summary><ul><li>`text`</li><li>`image-url`</li></ul></details></small></small> | The type of the content part. |
</div>

<h4 id="text-generation-chat-image-url">Image URL <sup><small><small>Referenced in <a href="#text-generation-chat-content">Content</a></small></small></sup></h4>

The image URL

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| URL | `url` | string | Either a URL of the image or the base64 encoded image data. |
</div>

</details>


### Text to Image

Generate images from input text prompts.

<h4 id="text-to-image-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_TEXT_TO_IMAGE` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Prompt (required) | `prompt` | string | The prompt text. |
| Samples | `samples` | integer | The number of generated samples, default is 1. |
| Seed | `seed` | integer | The seed, default is 0. |
| Aspect Ratio | `negative-prompt` | string | Keywords of what you do not wish to see in the output image. |
| Aspect Ratio | `aspect-ratio` | string<br/><small><small><details><summary>Enum values</summary><ul><li>`16:9`</li><li>`1:1`</li><li>`21:9`</li><li>`2:3`</li><li>`3:2`</li><li>`4:5`</li><li>`5:4`</li><li>`9:16`</li><li>`9:21`</li></ul></details></small></small> | Controls the aspect ratio of the generated image. Defaults to 1:1. |
</div>

<h4 id="text-to-image-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Images | `images` | array[image/jpeg] | Images. |
</div>


### Visual Question Answering

Answer questions based on a prompt and an image.

<h4 id="visual-question-answering-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_VISUAL_QUESTION_ANSWERING` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Prompt (required) | `prompt` | string | The prompt text. |
| System Message | `system-message` | string | The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model's behavior is using a generic message as "You are a helpful assistant.". |
| Prompt Images | `prompt-images` | array[string] | The prompt images. |
| Chat History | `chat-history` | array[object ([chat-history](#visual-question-answering-chat-message))] | Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: \{"role": "The message role, i.e. `system`, `user` or `assistant`", "content": "message content"\}. |
| Seed | `seed` | integer | The seed. |
| Temperature | `temperature` | number | The temperature for sampling. |
| Max New Tokens | `max-new-tokens` | integer | The maximum number of tokens for model to generate. |
</div>

<h4 id="visual-question-answering-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Text | `text` | string | Text. |
</div>

<details>
<summary> Referenced Objects</summary>
<h4 id="visual-question-answering-chat-message">Chat Message <sup><small><small>Referenced in <a href="#visual-question-answering-input">Input</a></small></small></sup></h4>

Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: \{"role": "The message role, i.e. `system`, `user` or `assistant`", "content": "message content"\}.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Role | `role` | string | The message role, i.e. 'system', 'user' or 'assistant'. |
| Content | `content` | array[object ([content](#visual-question-answering-content))] | The message content. |
</div>

<h4 id="visual-question-answering-content">Content <sup><small><small>Referenced in <a href="#visual-question-answering-chat-message">Chat Message</a></small></small></sup></h4>

The message content.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Image URL | `image-url` | object ([chat-message](#visual-question-answering-chat-message)) | The image URL |
| Text | `text` | string | The text content. |
| Type | `type` | string<br/><small><small><details><summary>Enum values</summary><ul><li>`text`</li><li>`image-url`</li></ul></details></small></small> | The type of the content part. |
</div>

<h4 id="visual-question-answering-image-url">Image URL <sup><small><small>Referenced in <a href="#visual-question-answering-content">Content</a></small></small></sup></h4>

The image URL

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| URL | `url` | string | Either a URL of the image or the base64 encoded image data. |
</div>

</details>


### Chat

Generate texts from input text prompts and chat history.

<h4 id="chat-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_CHAT` |
| Model Name (required) | `model-name` | string | The Instill Model model to be used. |
| Prompt (required) | `prompt` | string | The prompt text. |
| System Message | `system-message` | string | The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model's behavior is using a generic message as "You are a helpful assistant.". |
| Prompt Images | `prompt-images` | array[string] | The prompt images. |
| Chat History | `chat-history` | array[object ([chat-history](#chat-chat-message))] | Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: \{"role": "The message role, i.e. `system`, `user` or `assistant`", "content": "message content"\}. |
| Seed | `seed` | integer | The seed. |
| Temperature | `temperature` | number | The temperature for sampling. |
| Max New Tokens | `max-new-tokens` | integer | The maximum number of tokens for model to generate. |
</div>

<h4 id="chat-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Text | `text` | string | Text. |
</div>

<details>
<summary> Referenced Objects</summary>
<h4 id="chat-chat-message">Chat Message <sup><small><small>Referenced in <a href="#chat-input">Input</a></small></small></sup></h4>

Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: \{"role": "The message role, i.e. `system`, `user` or `assistant`", "content": "message content"\}.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Role | `role` | string | The message role, i.e. 'system', 'user' or 'assistant'. |
| Content | `content` | array[object ([content](#chat-content))] | The message content. |
</div>

<h4 id="chat-content">Content <sup><small><small>Referenced in <a href="#chat-chat-message">Chat Message</a></small></small></sup></h4>

The message content.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Image URL | `image-url` | object ([chat-message](#chat-chat-message)) | The image URL |
| Text | `text` | string | The text content. |
| Type | `type` | string<br/><small><small><details><summary>Enum values</summary><ul><li>`text`</li><li>`image-url`</li></ul></details></small></small> | The type of the content part. |
</div>

<h4 id="chat-image-url">Image URL <sup><small><small>Referenced in <a href="#chat-content">Content</a></small></small></sup></h4>

The image URL

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| URL | `url` | string | Either a URL of the image or the base64 encoded image data. |
</div>

</details>


### Embedding

This task refers to the process of generating vector embeddings from input data, which can be text or images. This transformation converts the data into a dense, fixed-length numerical representation that captures the essential features of the original input. These embeddings are typically used in machine learning tasks to represent complex data in a more structured, simplified form.

<h4 id="embedding-input">Input</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_EMBEDDING` |
| Data (required) | `data` | object ([data](#embedding-data)) | Input data. |
| Parameter | `parameter` | object ([parameter](#embedding-parameter)) | Input parameter. |
</div>

<h4 id="embedding-output">Output</h4>
<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Data | `data` | object ([data](#embedding-data)) | Output data. |
</div>

<details>
<summary> Referenced Objects</summary>
<h4 id="embedding-data">Data <sup><small><small>Referenced in <a href="#embedding-input">Input</a>, <a href="#embedding-output">Output</a></small></small></sup></h4>

Input data.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Model | `model` | string | The model to be used for generating embeddings. It should be `namespace/model-name/version`. i.e. `abrc/yolov7-stomata/v0.1.0`. You can see the version from the Versions tab of Model page. |
| Embeddings | `embeddings` | array[object] | List of input data to be embedded. |
</div>

<h4 id="embedding-embeddings">Embeddings <sup><small><small>Referenced in <a href="#embedding-data">Data</a></small></small></sup></h4>

List of generated embeddings.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Index | `index` | integer | The index of the embedding vector in the array. |
| Embedding Vector | `vector` | array[number] | The embedding vector. |
| Created | `created` | integer | The Unix timestamp (in seconds) of when the embedding was created. |
</div>

<h4 id="embedding-parameter">Parameter <sup><small><small>Referenced in <a href="#embedding-input">Input</a></small></small></sup></h4>

Input parameter.

<div class="markdown-col-no-wrap" data-col-1 data-col-2>

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Data Format | `format` | string<br/><small><small><details><summary>Enum values</summary><ul><li>`float`</li><li>`base64`</li></ul></details></small></small> | The data format of the embeddings. Defaults to float. |
| Dimensions | `dimensions` | integer | Number of dimensions in the output embedding vectors. |
| Input Type | `input-type` | string | The type of input data to be embedded (e.g., query, document). |
| Truncate | `truncate` | string<br/><small><small><details><summary>Enum values</summary><ul><li>`None`</li><li>`End`</li><li>`Start`</li></ul></details></small></small> | How to handle inputs longer than the max token length. Defaults to 'End'. |
</div>

</details>



